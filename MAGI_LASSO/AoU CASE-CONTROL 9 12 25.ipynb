{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MAGI batch: keep ALL positives + 4x negatives\n",
    "# Titles/filenames use REAL NAMES (not codes)\n",
    "# ============================================\n",
    "import os, math, numpy as np, pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f967a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- CONFIG -------------\n",
    "BASE      = \"./testing_YL\"\n",
    "\n",
    "# Mapping: code -> pretty name (use your list)\n",
    "TARGET_NAME = {\n",
    "#    \"dx_SNOMED_109378008\": \"Mesothelioma (malignant, clinical disorder)\",\n",
    "    \"dx_SNOMED_254645002\": \"Malignant mesothelioma of pleura\",\n",
    "#    \"dx_SNOMED_109853004\": \"Mesothelioma of peritoneum\",\n",
    "#    \"dx_SNOMED_109372009\": \"Benign neoplasm of mesothelial tissue of pleura\",\n",
    "}\n",
    "\n",
    "TARGETS = list(TARGET_NAME.keys())\n",
    "\n",
    "# Coefficient CSVs live here, one per target\n",
    "# Example filename: ./testing_YL/NIDA/redo/magi_coef_dx_SNOMED_15167005_byTE.csv\n",
    "COEF_PATTERN = os.path.join(BASE, \"Mesothelioma/magi_coef\", \"magi_coef_{target}.csv\")\n",
    "\n",
    "# Output folders\n",
    "OUT_DIR      = os.path.join(BASE, \"Mesothelioma/magi_out\")\n",
    "PNG_DIR      = os.path.join(OUT_DIR, \"png\")\n",
    "CSV_DIR      = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(PNG_DIR, exist_ok=True)\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "\n",
    "# Sampling plan\n",
    "NEG_MULT   = 4            # keep ALL positives + 4x negatives\n",
    "RNG_SEED   = 42\n",
    "\n",
    "# collage settings\n",
    "COLS_GRID  = 2            # ROC images per row in collage\n",
    "IMG_SCALE  = 0.75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- UTILS ----------\n",
    "def banner(txt):\n",
    "    bar = \"=\" * max(12, len(txt) + 4)\n",
    "    print(f\"\\n{bar}\\n{txt}\\n{bar}\")\n",
    "\n",
    "def subhead(txt):\n",
    "    print(f\"\\n--- {txt} ---\")\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    return \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\") else \"_\" for ch in s)\n",
    "\n",
    "def qtiles(x):\n",
    "    x = np.asarray(x)\n",
    "    return np.quantile(x, [0, 0.01, 0.25, 0.5, 0.75, 0.99, 1.0])\n",
    "\n",
    "def preview_active_codes(X_csr, feature_codes, row_indices, k=8):\n",
    "    \"\"\"Print up to k active codes for a few rows.\"\"\"\n",
    "    for i in row_indices:\n",
    "        start, end = X_csr.indptr[i], X_csr.indptr[i+1]\n",
    "        cols = X_csr.indices[start:end]\n",
    "        codes_list = [feature_codes[j] for j in cols[:k]]\n",
    "        print(f\"   row {i}: n_active={len(cols)}  sample_active={codes_list}\")\n",
    "\n",
    "def load_magi_betas(coef_csv):\n",
    "    df = pd.read_csv(coef_csv)\n",
    "    def pick(df, opts):\n",
    "        for c in opts:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        raise KeyError(f\"Missing any of {opts} in {coef_csv}. Found: {list(df.columns)}\")\n",
    "    code_col = pick(df, [\"concept_code\",\"standard_concept_code\",\"predictor\",\"feature\",\"term\",\"name\"])\n",
    "    beta_col = pick(df, [\"coef\",\"coefficient\",\"beta\",\"estimate\",\"b\",\"value\"])\n",
    "    df[code_col] = df[code_col].astype(str).str.strip()\n",
    "    is_int = df[code_col].str.lower().isin([\"(intercept)\",\"intercept\",\"const\",\"(const)\",\"bias\"])\n",
    "    intercept = float(df.loc[is_int, beta_col].iloc[0]) if is_int.any() else 0.0\n",
    "    coef_map  = dict(zip(df.loc[~is_int, code_col], df.loc[~is_int, beta_col].astype(float)))\n",
    "    return intercept, coef_map\n",
    "\n",
    "def sample_fixed_pos_neg(y, n_pos=1000, n_neg=4000, seed=42):\n",
    "    \"\"\"\n",
    "    Sample up to 1,000 positives; if fewer are available, use all of them.\n",
    "    Always sample negatives = 4 × (#positives actually sampled), capped by availability.\n",
    "    (n_neg is ignored for size; kept for backward compatibility.)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pos_idx = np.where(y == 1)[0]\n",
    "    neg_idx = np.where(y == 0)[0]\n",
    "    if pos_idx.size == 0:\n",
    "        raise ValueError(\"No positives for this target.\")\n",
    "\n",
    "    take_pos = min(n_pos, pos_idx.size)\n",
    "    take_neg = min(4 * take_pos, neg_idx.size)  # <-- key change: 4× positives\n",
    "\n",
    "    sel_pos = rng.choice(pos_idx, size=take_pos, replace=False)\n",
    "    sel_neg = rng.choice(neg_idx, size=take_neg, replace=False)\n",
    "    sel = np.concatenate([sel_pos, sel_neg])\n",
    "    rng.shuffle(sel)\n",
    "    return sel\n",
    "\n",
    "\n",
    "def score_from_betas(X_sub, feature_codes, betas_map, intercept):\n",
    "    feat = np.array(feature_codes, dtype=str)\n",
    "    mask = np.isin(feat, list(betas_map.keys()))\n",
    "    idx  = np.where(mask)[0]\n",
    "    if idx.size == 0: raise ValueError(\"No overlap between features and MAGI coefficients.\")\n",
    "    betas = np.array([betas_map[c] for c in feat[idx]], dtype=float)\n",
    "    lp = intercept + X_sub[:, idx].dot(betas)      # (n,)\n",
    "    p  = expit(np.asarray(lp).ravel())\n",
    "    return np.asarray(lp).ravel(), p, idx, betas\n",
    "\n",
    "def plot_roc(y_true, p_hat, title, out_png, out_svg):\n",
    "    fpr, tpr, _ = roc_curve(y_true, p_hat)\n",
    "    auc = roc_auc_score(y_true, p_hat)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\")\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\", linewidth=1)\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title); plt.legend(loc=\"lower right\"); plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(out_svg, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return auc\n",
    "\n",
    "def drop_constants_and_duplicates_for_sample(X_csr, feature_codes):\n",
    "    \"\"\"\n",
    "    On the sampled matrix (rows = selected patients):\n",
    "      - Drop all-zero columns\n",
    "      - Drop perfectly duplicate columns (exact same sparsity pattern & values)\n",
    "    Returns reduced X, reduced feature_codes, and a boolean keep_mask aligned to original feature_codes.\n",
    "    \"\"\"\n",
    "    n_rows, n_cols = X_csr.shape\n",
    "    # drop all-zero quickly\n",
    "    nnz = np.asarray((X_csr != 0).sum(axis=0)).ravel()\n",
    "    keep_mask = (nnz > 0)\n",
    "\n",
    "    # check duplicates among remaining columns via CSC hashes\n",
    "    X_csc = X_csr[:, keep_mask].tocsc()\n",
    "    sub_keep = np.ones(X_csc.shape[1], dtype=bool)\n",
    "    seen = {}\n",
    "    for j in range(X_csc.shape[1]):\n",
    "        s, e = X_csc.indptr[j], X_csc.indptr[j+1]\n",
    "        idx = X_csc.indices[s:e]\n",
    "        dat = X_csc.data[s:e]\n",
    "        key = (idx.tobytes(), dat.tobytes())\n",
    "        if key in seen:\n",
    "            sub_keep[j] = False\n",
    "        else:\n",
    "            seen[key] = j\n",
    "\n",
    "    # map back to original feature space\n",
    "    keep_idx = np.where(keep_mask)[0]\n",
    "    keep_mask_final = np.zeros(n_cols, dtype=bool)\n",
    "    keep_mask_final[keep_idx[sub_keep]] = True\n",
    "\n",
    "    X_red = X_csr[:, keep_mask_final]\n",
    "    feats_red = feature_codes[keep_mask_final]\n",
    "    dropped = n_cols - int(keep_mask_final.sum())\n",
    "    print(f\"[INFO] LASSO collinearity cleanup: kept {X_red.shape[1]:,}/{n_cols:,} features \"\n",
    "          f\"(dropped {dropped:,} all-zero/duplicate).\")\n",
    "    return X_red, feats_red, keep_mask_final\n",
    "\n",
    "# large x and y, no title\n",
    "def plot_roc(y_true, p_hat, title, out_png, out_svg):\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, p_hat)\n",
    "    auc = roc_auc_score(y_true, p_hat)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\")\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\", linewidth=1)\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "    # Larger + bold axis labels and ticks; no title\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.xticks(fontsize=14, fontweight=\"bold\")\n",
    "    plt.yticks(fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.4)\n",
    "\n",
    "    plt.legend(loc=\"lower right\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(out_svg, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return auc\n",
    "\n",
    "# ---------- LOAD DESIGN ONCE ----------\n",
    "banner(\"LOAD DESIGN\")\n",
    "X_full  = load_npz(f\"{BASE}/Lasso_X.npz\").tocsr().astype(np.float32)\n",
    "persons = pd.read_csv(f\"{BASE}/person_index.csv\")[\"person_id\"].astype(str).to_numpy()\n",
    "codes   = pd.read_csv(f\"{BASE}/code_index.csv\")[\"concept_code\"].astype(str).to_numpy()\n",
    "print(f\"[INFO] Matrix: persons={X_full.shape[0]:,}  codes={X_full.shape[1]:,}\")\n",
    "if len(persons) != X_full.shape[0] or len(codes) != X_full.shape[1]:\n",
    "    raise ValueError(\"[ERROR] person/code indices do not match matrix shape.\")\n",
    "\n",
    "# ---------- RUN PER TARGET ----------\n",
    "\n",
    "summary = []\n",
    "for tcode in TARGETS:\n",
    "    pretty = TARGET_NAME.get(tcode, tcode)\n",
    "    banner(f\"TARGET {tcode} — {pretty}\")\n",
    "\n",
    "    # SECTION A: labels\n",
    "    subhead(\"A) Label vector from full design\")\n",
    "    idx_y = np.where(codes == tcode)[0]\n",
    "    if idx_y.size == 0:\n",
    "        print(f\"[SKIP] Target not found in code_index.csv → {tcode}\")\n",
    "        continue\n",
    "    y_full = X_full[:, idx_y[0]].toarray().ravel().astype(np.int8)\n",
    "    print(f\"[INFO] y_full: n={y_full.size:,}  pos={int(y_full.sum()):,}  \"\n",
    "          f\"prev={y_full.mean():.4f}\")\n",
    "\n",
    "    # SECTION B: predictors (keep all except DV)\n",
    "    subhead(\"B) Predictor matrix (keep all columns except DV)\")\n",
    "    mask_pred = (codes != tcode)\n",
    "    X = X_full[:, mask_pred]\n",
    "    feature_codes = codes[mask_pred]\n",
    "    print(f\"[INFO] Predictors: persons={X.shape[0]:,}  features={X.shape[1]:,}\")\n",
    "    print(f\"[CHECK] DV in features? {tcode in feature_codes} (should be False)\")\n",
    "    \n",
    "    # SECTION C: sampling (1k pos + 4k neg, random; SAME SAMPLE for MAGI & LASSO)\n",
    "    subhead(\"C) Sampling (1,000 positives + 4,000 negatives)\")\n",
    "    sel = sample_fixed_pos_neg(y_full, n_pos=1000, n_neg=4000, seed=RNG_SEED)\n",
    "    X_sub       = X[sel, :]\n",
    "    y_sub       = y_full[sel].astype(np.int8)\n",
    "    persons_sub = persons[sel]\n",
    "    n_rows      = X_sub.shape[0]\n",
    "    n_pos_sub   = int(y_sub.sum())\n",
    "    n_neg_sub   = n_rows - n_pos_sub\n",
    "    print(f\"[INFO] subset: n={n_rows:,}  pos={n_pos_sub:,}  neg={n_neg_sub:,}  \"\n",
    "          f\"ratio≈{(n_neg_sub/max(n_pos_sub,1)):.2f}:1  PR-baseline={y_sub.mean():.4f}\")\n",
    "    try:\n",
    "        preview_active_codes(X_sub, feature_codes, row_indices=range(min(3, n_rows)), k=8)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] preview_active_codes failed: {e}\")\n",
    "\n",
    "\n",
    "    # SECTION D: coefficients (MAGI)\n",
    "    subhead(\"D) Load MAGI coefficients\")\n",
    "    coef_csv = COEF_PATTERN.format(target=tcode)\n",
    "    if not os.path.exists(coef_csv):\n",
    "        print(f\"[SKIP] Coef file missing: {coef_csv}\")\n",
    "        continue\n",
    "    intercept, coef_map = load_magi_betas(coef_csv)\n",
    "    print(f\"[INFO] Coefs: intercept={intercept:.6f}  n_features={len(coef_map):,}\")\n",
    "    for k,(cc,bb) in enumerate(list(coef_map.items())[:5]):\n",
    "        print(f\"   beta[{cc}] = {bb:.6f}\")\n",
    "    if \"(intercept)\" not in open(coef_csv, 'r', encoding=\"utf-8\", errors=\"ignore\").read():\n",
    "        print(\"[NOTE] No explicit '(intercept)' row in CSV; using 0.0 if not found.\")\n",
    "\n",
    "    # SECTION E: alignment & scoring (MAGI)\n",
    "    subhead(\"E) Align & score (MAGI)\")\n",
    "    try:\n",
    "        lp, p_hat, idx_cols, betas_vec = score_from_betas(X_sub, feature_codes, coef_map, intercept)\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] MAGI scoring failed (no overlap or other issue): {e}\")\n",
    "        continue\n",
    "    n_overlap = idx_cols.size\n",
    "    print(f\"[INFO] overlap with predictors = {n_overlap:,} columns\")\n",
    "    print(f\"[INFO] first 5 aligned columns: {[feature_codes[i] for i in idx_cols[:5]]}\")\n",
    "    print(f\"[INFO] first 5 aligned betas:   {[float(b) for b in betas_vec[:5]]}\")\n",
    "\n",
    "    # SECTION F: metrics & distributions (MAGI)\n",
    "    subhead(\"F) Metrics & probability distribution (MAGI)\")\n",
    "    auc    = roc_auc_score(y_sub, p_hat)\n",
    "    pr_auc = average_precision_score(y_sub, p_hat)\n",
    "    q = qtiles(p_hat)\n",
    "    print(f\"[RESULT] MAGI AUC={auc:.4f}  |  PR-AUC={pr_auc:.4f}  (baseline={y_sub.mean():.4f})\")\n",
    "    print(f\"[DIST] prob quantiles: min={q[0]:.4g}, p1={q[1]:.4g}, p25={q[2]:.4g}, \"\n",
    "          f\"median={q[3]:.4g}, p75={q[4]:.4g}, p99={q[5]:.4g}, max={q[6]:.4g}\")\n",
    "    print(f\"[COUNT] prob>=0.999: {(p_hat>=0.999).sum()}  |  prob<=0.001: {(p_hat<=0.001).sum()}\")\n",
    "\n",
    "    # SECTION G: save predictions (MAGI)\n",
    "    subhead(\"G) Save per-person predictions (MAGI)\")\n",
    "    safe = safe_name(pretty)\n",
    "    pred_csv = os.path.join(CSV_DIR, f\"pred_{safe}.csv\")\n",
    "    pd.DataFrame({\n",
    "        \"person_id\": persons_sub,\n",
    "        \"y_true\": y_sub.astype(int),\n",
    "        \"score_logit\": lp,\n",
    "        \"prob\": p_hat\n",
    "    }).to_csv(pred_csv, index=False)\n",
    "    print(f\"[SAVE] predictions → {pred_csv}\")\n",
    "    print(pd.read_csv(pred_csv).head(10))\n",
    "\n",
    "    # SECTION H: plots (MAGI)\n",
    "    subhead(\"H) ROC plots (MAGI) PNG/SVG\")\n",
    "    png_path = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}.png\"))\n",
    "    svg_path = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}.svg\"))\n",
    "    _auc = plot_roc(y_sub, p_hat, pretty, png_path, svg_path)\n",
    "    print(f\"[SAVE] ROC → {png_path}\")\n",
    "    print(f\"[SAVE] ROC → {svg_path}\")\n",
    "\n",
    "    # SECTION I: LASSO (ALL FEATURES, no SAFE) on the SAME SAMPLE\n",
    "    subhead(\"I) LASSO: all features (drop constants/duplicates), 5-fold CV\")\n",
    "    try:\n",
    "        Xs = X_sub.tocsr().astype(np.float32)\n",
    "\n",
    "        # Remove constants & perfectly duplicate columns (on the sample only)\n",
    "        X_lasso, feat_lasso, keep_mask = drop_constants_and_duplicates_for_sample(Xs, feature_codes)\n",
    "\n",
    "        if X_lasso.shape[1] == 0:\n",
    "            print(\"[SKIP] No usable features after cleanup; skipping LASSO.\")\n",
    "            lasso_cv_auc = np.nan; lasso_auc = np.nan; lasso_pr = np.nan\n",
    "            lasso_pred_csv = \"\"; lasso_coef_csv = \"\"; lasso_roc_png = \"\"; lasso_pr_png = \"\"\n",
    "        else:\n",
    "            # Fit Logistic LASSO with 5-fold CV on all remaining features\n",
    "            clf = LogisticRegressionCV(\n",
    "                Cs=np.logspace(-3, 3, 12),\n",
    "                cv=5,\n",
    "                penalty=\"l1\",\n",
    "                solver=\"saga\",\n",
    "                scoring=\"roc_auc\",\n",
    "                max_iter=2000,\n",
    "                n_jobs=-1,\n",
    "                random_state=RNG_SEED,\n",
    "                refit=True,\n",
    "                fit_intercept=True,\n",
    "            ).fit(X_lasso, y_sub)\n",
    "\n",
    "            # CV summary\n",
    "            scores_mat = clf.scores_[1]                 # (folds × Cs)\n",
    "            mean_auc_per_C = scores_mat.mean(axis=0)\n",
    "            best_idx = int(np.argmax(mean_auc_per_C))\n",
    "            lasso_cv_auc = float(mean_auc_per_C[best_idx])\n",
    "            best_C = float(np.atleast_1d(clf.C_)[0])\n",
    "            print(f\"[MODEL] LASSO best_C={best_C:.6g}  CV-AUC={lasso_cv_auc:.4f}\")\n",
    "\n",
    "            # Refit predictions & metrics (on the sampled data)\n",
    "            p_hat_lasso = clf.predict_proba(X_lasso)[:, 1]\n",
    "            lasso_auc   = roc_auc_score(y_sub, p_hat_lasso)\n",
    "            lasso_pr    = average_precision_score(y_sub, p_hat_lasso)\n",
    "            print(f\"[RESULT] LASSO Refit AUC={lasso_auc:.4f} | PR-AUC={lasso_pr:.4f} (baseline={y_sub.mean():.4f})\")\n",
    "\n",
    "            # Save LASSO predictions\n",
    "            safe = safe_name(pretty)\n",
    "            lasso_pred_csv = os.path.join(CSV_DIR, f\"pred_{safe}_LASSO.csv\")\n",
    "            pd.DataFrame({\n",
    "                \"person_id\": persons_sub,\n",
    "                \"y_true\": y_sub.astype(int),\n",
    "                \"prob_lasso\": p_hat_lasso\n",
    "            }).to_csv(lasso_pred_csv, index=False)\n",
    "            print(f\"[SAVE] LASSO predictions → {lasso_pred_csv}\")\n",
    "\n",
    "            # Save LASSO coefficients (non-zero only)\n",
    "            coef = clf.coef_.ravel(); intercept_l = float(clf.intercept_.ravel()[0])\n",
    "            nz = np.where(coef != 0)[0]\n",
    "            coef_df = pd.DataFrame({\"feature\": feat_lasso[nz], \"coef\": coef[nz]}) \\\n",
    "                        .sort_values(\"coef\", key=np.abs, ascending=False)\n",
    "            coef_df.loc[-1] = {\"feature\": \"(intercept)\", \"coef\": intercept_l}\n",
    "            coef_df.index = coef_df.index + 1\n",
    "            lasso_coef_csv = os.path.join(OUT_DIR, f\"lasso_coef_{safe}.csv\")\n",
    "            coef_df.to_csv(lasso_coef_csv, index=False)\n",
    "            print(f\"[SAVE] LASSO coefficients → {lasso_coef_csv} (nonzero={len(nz)} of {len(coef)})\")\n",
    "\n",
    "            # LASSO ROC & PR plots\n",
    "            lasso_roc_png = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}_LASSO.png\"))\n",
    "            lasso_roc_svg = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}_LASSO.svg\"))\n",
    "            lasso_pr_png  = os.path.abspath(os.path.join(PNG_DIR, f\"PR_{safe}_LASSO.png\"))\n",
    "            lasso_pr_svg  = os.path.abspath(os.path.join(PNG_DIR, f\"PR_{safe}_LASSO.svg\"))\n",
    "            _ = plot_roc(y_sub, p_hat_lasso, f\"{pretty} (LASSO, CV=5)\", lasso_roc_png, lasso_roc_svg)\n",
    "            _ = plot_pr(y_sub, p_hat_lasso, f\"{pretty}\", lasso_pr_png, lasso_pr_svg)\n",
    "            print(f\"[SAVE] LASSO ROC → {lasso_roc_png}\")\n",
    "            print(f\"[SAVE] LASSO PR  → {lasso_pr_png}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] LASSO failed: {e}\")\n",
    "        lasso_cv_auc = np.nan; lasso_auc = np.nan; lasso_pr = np.nan\n",
    "        lasso_pred_csv = \"\"; lasso_coef_csv = \"\"; lasso_roc_png = \"\"; lasso_pr_png = \"\"\n",
    "        \n",
    "    \n",
    "    summary.append({\n",
    "        \"target_code\": tcode,\n",
    "        \"target_name\": pretty,\n",
    "        \"n_cases\": n_rows,\n",
    "        \"n_pos\": n_pos_sub,\n",
    "        \"n_neg\": n_neg_sub,\n",
    "        \"feature_overlap\": n_overlap,         # MAGI overlap info\n",
    "        \"AUC\": auc,                           # MAGI\n",
    "        \"PR_AUC\": pr_auc,                     # MAGI\n",
    "        \"PR_baseline\": y_sub.mean(),\n",
    "        \"coef_csv\": coef_csv,                 # MAGI coef csv path\n",
    "        \"pred_csv\": pred_csv,                 # MAGI pred csv path\n",
    "        \"roc_png\": os.path.abspath(png_path), # MAGI ROC path (abs)\n",
    "        # ---- LASSO fields ----\n",
    "        \"LASSO_CV_AUC\": lasso_cv_auc,\n",
    "        \"LASSO_Refit_AUC\": lasso_auc,\n",
    "        \"LASSO_PR_AUC\": lasso_pr,\n",
    "        \"LASSO_pred_csv\": lasso_pred_csv,\n",
    "        \"LASSO_coef_csv\": lasso_coef_csv,\n",
    "        \"LASSO_roc_png\": lasso_roc_png if 'lasso_roc_png' in locals() else \"\",\n",
    "        \"LASSO_pr_png\":  lasso_pr_png  if 'lasso_pr_png'  in locals() else \"\",\n",
    "    })\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
