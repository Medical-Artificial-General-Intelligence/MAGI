{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4374ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 9 25\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.special import expit\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score, accuracy_score,\n",
    ")\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "BASE = \"./testing_YL\"\n",
    "\n",
    "TARGET_NAME = {\n",
    "    \"dx_SNOMED_254645002\": \"Malignant mesothelioma of pleura\",\n",
    "}\n",
    "TARGETS = list(TARGET_NAME.keys())\n",
    "\n",
    "# Example: ./testing_YL/Mesothelioma/magi_coef/magi_coef_<target>.csv\n",
    "COEF_PATTERN = os.path.join(BASE, \"Mesothelioma/magi_coef\", \"magi_coef_{target}_nonzero.csv\")\n",
    "\n",
    "# Output folders\n",
    "OUT_DIR      = os.path.join(BASE, \"Mesothelioma/magi_out\")\n",
    "PNG_DIR      = os.path.join(OUT_DIR, \"png\")\n",
    "CSV_DIR      = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(PNG_DIR, exist_ok=True)\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "\n",
    "SUMMARY_CSV = os.path.join(OUT_DIR, \"summary_per_target_and_bootstrap.csv\")\n",
    "\n",
    "RNG_SEED = 42\n",
    "NEG_MULT = 4\n",
    "N_BOOT   = 100\n",
    "\n",
    "# selection ranking mode\n",
    "RANK_MODE = \"prevalence\"  # or \"beta\"\n",
    "\n",
    "# SAFE presence thresholds (mild/strict)\n",
    "SAFE_MIN_TOTAL_COUNT_EPV_5_9  = 2\n",
    "SAFE_MIN_POS_CARRIERS_EPV_5_9 = 1\n",
    "SAFE_MIN_TOTAL_COUNT_EPV_LT5  = 3\n",
    "SAFE_MIN_POS_CARRIERS_EPV_LT5 = 2\n",
    "# -------------------- EPV CONFIG --------------------\n",
    "EPV_TARGET = 9          # set 5 (current ask) or 9 (old behavior)\n",
    "EPV_MIN    = 5          # lower bound in SAFE band (typically 5)\n",
    "\n",
    "# Bootstrap policy: run bootstrap if EPV <= (multiplier * EPV_TARGET)\n",
    "BOOTSTRAP_EPV_MAX_MULTIPLIER = 2.0  # (e.g., with EPV_TARGET=5 → run if EPV<=10)\n",
    "\n",
    "# Choose SAFE presence thresholds by EPV regime\n",
    "SAFE_POLICY = \"mild\"  # (\"mild\" here just uses the table below; keep as-is unless you want a switch)\n",
    "def _safe_thresholds(epv_target: int):\n",
    "    # You already defined these constants above\n",
    "    if epv_target >= 5:\n",
    "        return SAFE_MIN_TOTAL_COUNT_EPV_5_9, SAFE_MIN_POS_CARRIERS_EPV_5_9\n",
    "    else:\n",
    "        return SAFE_MIN_TOTAL_COUNT_EPV_LT5,  SAFE_MIN_POS_CARRIERS_EPV_LT5\n",
    "\n",
    "MIN_TOTAL_COUNT, MIN_POS_CARRIERS = _safe_thresholds(EPV_TARGET)\n",
    "\n",
    "# -------------------- UTILS --------------------\n",
    "def banner(txt):\n",
    "    bar = \"=\" * max(12, len(txt) + 4)\n",
    "    print(f\"\\n{bar}\\n{txt}\\n{bar}\")\n",
    "\n",
    "def subhead(txt):\n",
    "    print(f\"\\n--- {txt} ---\")\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    return \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\") else \"_\" for ch in s)\n",
    "\n",
    "def plot_roc(y_true, p_hat, title, out_png, out_svg):\n",
    "    fpr, tpr, _ = roc_curve(y_true, p_hat)\n",
    "    auc_val = roc_auc_score(y_true, p_hat)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={auc_val:.3f}\")\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\", linewidth=1)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.ylabel(\"True Positive Rate\",  fontsize=16, fontweight=\"bold\")\n",
    "    plt.xticks(fontsize=14, fontweight=\"bold\")\n",
    "    plt.yticks(fontsize=14, fontweight=\"bold\")\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.4)\n",
    "    plt.legend(loc=\"lower right\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(out_svg, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return float(auc_val)\n",
    "\n",
    "def load_magi_betas(coef_csv):\n",
    "    df = pd.read_csv(coef_csv)\n",
    "    def pick(df, opts):\n",
    "        for c in opts:\n",
    "            if c in df.columns: return c\n",
    "        raise KeyError(f\"Missing any of {opts} in {coef_csv}. Found: {list(df.columns)}\")\n",
    "    code_col = pick(df, [\"concept_code\",\"standard_concept_code\",\"predictor\",\"feature\",\"term\",\"name\"])\n",
    "    beta_col = pick(df, [\"coef\",\"coefficient\",\"beta\",\"estimate\",\"b\",\"value\"])\n",
    "    df[code_col] = df[code_col].astype(str).str.strip()\n",
    "    is_int = df[code_col].str.lower().isin([\"(intercept)\",\"intercept\",\"const\",\"(const)\",\"bias\"])\n",
    "    intercept = float(df.loc[is_int, beta_col].iloc[0]) if is_int.any() else 0.0\n",
    "    coef_map  = dict(zip(df.loc[~is_int, code_col], df.loc[~is_int, beta_col].astype(float)))\n",
    "    return intercept, coef_map\n",
    "\n",
    "def sample_fixed_pos_neg(y, n_pos=None, seed=RNG_SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pos_idx = np.where(y == 1)[0]\n",
    "    neg_idx = np.where(y == 0)[0]\n",
    "    if pos_idx.size == 0:\n",
    "        raise ValueError(\"No positives for this target.\")\n",
    "\n",
    "    if n_pos is None:                 # <-- support 'all positives'\n",
    "        take_pos = pos_idx.size\n",
    "        sel_pos = pos_idx\n",
    "    else:\n",
    "        take_pos = min(n_pos, pos_idx.size)\n",
    "        sel_pos = rng.choice(pos_idx, size=take_pos, replace=False)\n",
    "\n",
    "    take_neg = min(NEG_MULT * take_pos, neg_idx.size)\n",
    "    sel_neg = rng.choice(neg_idx, size=take_neg, replace=False)\n",
    "    sel = np.concatenate([sel_pos, sel_neg]); rng.shuffle(sel)\n",
    "    return sel\n",
    "\n",
    "def drop_constants_and_duplicates_for_sample(X_csr, feature_codes, verbose=True):\n",
    "    n_rows, n_cols = X_csr.shape\n",
    "    nnz = np.asarray((X_csr != 0).sum(axis=0)).ravel()\n",
    "    keep_mask = (nnz > 0)\n",
    "    X_csc = X_csr[:, keep_mask].tocsc()\n",
    "    sub_keep = np.ones(X_csc.shape[1], dtype=bool)\n",
    "    seen = {}\n",
    "    for j in range(X_csc.shape[1]):\n",
    "        s, e = X_csc.indptr[j], X_csc.indptr[j+1]\n",
    "        idx = X_csc.indices[s:e]\n",
    "        dat = X_csc.data[s:e]\n",
    "        key = (idx.tobytes(), dat.tobytes())\n",
    "        if key in seen:\n",
    "            sub_keep[j] = False\n",
    "        else:\n",
    "            seen[key] = j\n",
    "    keep_idx = np.where(keep_mask)[0]\n",
    "    keep_mask_final = np.zeros(n_cols, dtype=bool)\n",
    "    keep_mask_final[keep_idx[sub_keep]] = True\n",
    "    X_red = X_csr[:, keep_mask_final]\n",
    "    feats_red = feature_codes[keep_mask_final]\n",
    "    dropped = int(n_cols - keep_mask_final.sum())\n",
    "    if verbose:\n",
    "        print(f\"[INFO] LASSO/MAGI cleanup: kept {X_red.shape[1]:,}/{n_cols:,} features \"\n",
    "              f\"(dropped {dropped:,} all-zero/duplicate).\")\n",
    "    return X_red, feats_red, keep_mask_final\n",
    "\n",
    "def compute_epv(n_pos: int, n_predictors: int) -> float:\n",
    "    if n_predictors <= 0:\n",
    "        return float('inf') if n_pos > 0 else 0.0\n",
    "    return float(n_pos) / float(n_predictors)\n",
    "\n",
    "# ------------ Selection: EPV-target=9 with SAFE to force EPV∈[5,9] ------------\n",
    "def select_and_trim_to_epv_range(\n",
    "    X_train, y_train, feature_codes, coef_map, *,\n",
    "    dv_code,\n",
    "    rank=\"prevalence\",\n",
    "    require_present=True,\n",
    "    min_total_count=1,\n",
    "    min_pos_carriers=0,\n",
    "    epv_target=9,\n",
    "    epv_min=5,\n",
    "    verbose=False,\n",
    "):\n",
    "    import math\n",
    "    import numpy as np\n",
    "\n",
    "    y_train = np.asarray(y_train).ravel().astype(int)\n",
    "    n_pos = int(np.sum(y_train == 1))\n",
    "    if n_pos == 0:\n",
    "        if verbose: print(\"[SEL] No positives; empty selection.\")\n",
    "        return X_train[:, :0], feature_codes[:0], np.array([], dtype=int), np.inf\n",
    "\n",
    "    # Bounds on #predictors to keep EPV in [epv_min, epv_target]\n",
    "    # n_min = preferred (EPV≈9); n_max = upper cap (EPV≥5)\n",
    "    n_min = max(1, int(math.ceil(n_pos / float(epv_target))))  # prefer this\n",
    "    n_max = max(n_min, int(math.floor(n_pos / float(epv_min))))# don’t exceed this\n",
    "\n",
    "    # MAGI mapping and DV exclusion\n",
    "    mapped_mask = np.array([c in coef_map for c in feature_codes], dtype=bool)\n",
    "    if dv_code is not None:\n",
    "        mapped_mask &= (feature_codes != dv_code)\n",
    "\n",
    "    cand_idx = np.where(mapped_mask)[0]\n",
    "    if cand_idx.size == 0:\n",
    "        if verbose: print(\"[SEL] No MAGI-mapped features (after DV exclusion).\")\n",
    "        return X_train[:, :0], feature_codes[:0], np.array([], dtype=int), np.inf\n",
    "\n",
    "    # presence/support filters\n",
    "    if require_present or (min_total_count > 1) or (min_pos_carriers > 0):\n",
    "        X_cand = X_train[:, cand_idx]\n",
    "        nnz_all = np.asarray((X_cand != 0).sum(axis=0)).ravel()\n",
    "        keep_local = (nnz_all >= max(1, min_total_count))\n",
    "        if min_pos_carriers > 0 and np.any(y_train == 1):\n",
    "            pos_rows = np.where(y_train == 1)[0]\n",
    "            nnz_pos = np.asarray((X_cand[pos_rows, :] != 0).sum(axis=0)).ravel()\n",
    "            keep_local &= (nnz_pos >= min_pos_carriers)\n",
    "        cand_idx = cand_idx[keep_local]\n",
    "        if cand_idx.size == 0:\n",
    "            if verbose: print(\"[SEL] After presence filters, no features remain.\")\n",
    "            return X_train[:, :0], feature_codes[:0], np.array([], dtype=int), np.inf\n",
    "\n",
    "    # ranking\n",
    "    if rank == \"prevalence\":\n",
    "        nnz = np.asarray((X_train[:, cand_idx] != 0).sum(axis=0)).ravel()\n",
    "        order_local = np.argsort(-nnz)\n",
    "        ordered_idx = cand_idx[order_local]\n",
    "    elif rank == \"beta\":\n",
    "        betas = np.array([coef_map[feature_codes[i]] for i in cand_idx], dtype=float)\n",
    "        order_local = np.argsort(-np.abs(betas))\n",
    "        ordered_idx = cand_idx[order_local]\n",
    "    else:\n",
    "        raise ValueError(\"rank must be 'prevalence' or 'beta'\")\n",
    "\n",
    "    # ---- CHANGED: prefer EPV≈9 (n_min), cap by EPV≥5 (n_max) and availability ----\n",
    "    n_avail = ordered_idx.size\n",
    "    k_cap   = min(n_max, n_avail)\n",
    "    k_final = min(n_min, k_cap)  # prefer n_min (EPV≈9)\n",
    "\n",
    "    if k_final <= 0:\n",
    "        if verbose: print(\"[SEL] No features after ranking/cap.\")\n",
    "        return X_train[:, :0], feature_codes[:0], np.array([], dtype=int), np.inf\n",
    "\n",
    "    keep_idx = ordered_idx[:k_final]\n",
    "\n",
    "    # cleanup (constants/duplicates)\n",
    "    X_top   = X_train[:, keep_idx]\n",
    "    feats_t = feature_codes[keep_idx]\n",
    "    X_used, feats_used, mask_final = drop_constants_and_duplicates_for_sample(\n",
    "        X_top.tocsr().astype(np.float32), feats_t\n",
    "    )\n",
    "    keep_idx_used = keep_idx[mask_final]\n",
    "\n",
    "    # If cleanup increased count (shouldn’t), clip; if it reduced count, accept (EPV will go up)\n",
    "    if X_used.shape[1] > k_final:\n",
    "        X_used        = X_used[:, :k_final]\n",
    "        feats_used    = feats_used[:k_final]\n",
    "        keep_idx_used = keep_idx_used[:k_final]\n",
    "\n",
    "    # Belt-and-suspenders: DV and identity checks\n",
    "    if feats_used.size and dv_code is not None:\n",
    "        leak = np.where(feats_used == dv_code)[0]\n",
    "        if leak.size:\n",
    "            keep_mask = np.ones(feats_used.size, dtype=bool); keep_mask[leak] = False\n",
    "            feats_used    = feats_used[keep_mask]\n",
    "            X_used        = X_used[:, keep_mask]\n",
    "            keep_idx_used = keep_idx_used[keep_mask]\n",
    "\n",
    "    yv = y_train.astype(np.int8)\n",
    "    drop_cols = []\n",
    "    for j in range(X_used.shape[1]):\n",
    "        col = X_used.getcol(j).toarray().ravel().astype(np.int8)\n",
    "        if np.array_equal(col, yv):\n",
    "            drop_cols.append(j)\n",
    "    if drop_cols:\n",
    "        keep_mask = np.ones(X_used.shape[1], dtype=bool); keep_mask[np.array(drop_cols)] = False\n",
    "        feats_used    = feats_used[keep_mask]\n",
    "        X_used        = X_used[:, keep_mask]\n",
    "        keep_idx_used = keep_idx_used[keep_mask]\n",
    "\n",
    "    # EPV\n",
    "    p_final = int(X_used.shape[1])\n",
    "    epv_final = (float(n_pos) / p_final) if p_final > 0 else np.inf\n",
    "    if verbose:\n",
    "        print(f\"[INFO] n_pos={n_pos}  n_min(pref@EPV≈{epv_target})={n_min}  \"\n",
    "              f\"n_max(EPV≥{epv_min})={n_max}  n_avail={n_avail}  \"\n",
    "              f\"k_final={p_final}  EPV={epv_final:.3f}\")\n",
    "\n",
    "    return X_used, feats_used, keep_idx_used.astype(int, copy=False), epv_final\n",
    "\n",
    "\n",
    "# -------------------- Bootstrap helpers --------------------\n",
    "def bootstrap_632plus_or_fallback(estimator, X, y, n_splits, scoring_func,\n",
    "                                  predict_proba, seed, clone_estimator=False):\n",
    "    try:\n",
    "        return bootstrap_point632_score(\n",
    "            estimator=estimator, X=X, y=y,\n",
    "            n_splits=n_splits, method=\".632+\",\n",
    "            scoring_func=scoring_func, predict_proba=predict_proba,\n",
    "            random_seed=seed, clone_estimator=clone_estimator\n",
    "        )\n",
    "    except ZeroDivisionError:\n",
    "        print(\"[WARN] .632+ failed (division by zero). Falling back to .632.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] .632+ failed ({e}). Falling back to .632.\")\n",
    "    return bootstrap_point632_score(\n",
    "        estimator=estimator, X=X, y=y,\n",
    "        n_splits=n_splits, method=\".632\",\n",
    "        scoring_func=scoring_func, predict_proba=predict_proba,\n",
    "        random_seed=seed, clone_estimator=clone_estimator\n",
    "    )\n",
    "\n",
    "# -------------------- Estimators (per-resample selection with EPV rules) --------------------\n",
    "class MagiBootstrapEstimatorCurrent(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, intercept, coef_map, feature_codes_all,\n",
    "                 dv_code,                      # <-- add this\n",
    "                 rank=\"prevalence\", n_frac=0.10, require_present=True,\n",
    "                 min_total_count=1, min_pos_carriers=0, verbose=False):\n",
    "        self.intercept = intercept\n",
    "        self.coef_map = coef_map\n",
    "        self.feature_codes_all = feature_codes_all\n",
    "        self.dv_code = dv_code               # <-- store it\n",
    "        self.rank = rank\n",
    "        self.n_frac = n_frac\n",
    "        self.require_present = require_present\n",
    "        self.min_total_count = min_total_count\n",
    "        self.min_pos_carriers = min_pos_carriers\n",
    "        self.verbose = verbose\n",
    "        self._feats_used = None\n",
    "        self._betas_used = None\n",
    "        self._feature_codes_all = None\n",
    "        self._intercept_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feature_codes_all = np.asarray(self.feature_codes_all)\n",
    "        coef_map = dict(self.coef_map)\n",
    "        intercept = float(self.intercept)\n",
    "\n",
    "        # selection with DV removed + EPV target 9, SAFE [5,9]\n",
    "        X_used, feats_used, _, _ = select_and_trim_to_epv_range(\n",
    "            X, y, feature_codes_all, coef_map,\n",
    "            dv_code=self.dv_code,                 # <-- pass dv_code\n",
    "            rank=self.rank, require_present=self.require_present,\n",
    "            min_total_count=MIN_TOTAL_COUNT, min_pos_carriers=MIN_POS_CARRIERS,\n",
    "            epv_target=EPV_TARGET, epv_min=EPV_MIN,              \n",
    "            verbose=self.verbose\n",
    "        )\n",
    "        assert self.dv_code not in set(feats_used), \"DV leaked into predictors! (MAGI)\"\n",
    "\n",
    "        if X_used.shape[1] == 0:\n",
    "            self._feats_used = np.array([], dtype=str)\n",
    "            self._betas_used = np.array([], dtype=float)\n",
    "            self._feature_codes_all = feature_codes_all\n",
    "            self._intercept_ = intercept\n",
    "            return self\n",
    "\n",
    "        self._feats_used = feats_used\n",
    "        self._betas_used = np.array([coef_map.get(c, 0.0) for c in feats_used], dtype=float)\n",
    "        self._feature_codes_all = feature_codes_all\n",
    "        self._intercept_ = intercept\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self._feats_used is None or self._feats_used.size == 0:\n",
    "            p = float(expit(self._intercept_))\n",
    "            return np.c_[1.0 - np.full(X.shape[0], p), np.full(X.shape[0], p)]\n",
    "        code_to_idx = {c: i for i, c in enumerate(self._feature_codes_all)}\n",
    "        col_idx = np.array([code_to_idx[c] for c in self._feats_used], dtype=int)\n",
    "        z = self._intercept_ + X[:, col_idx].dot(self._betas_used)\n",
    "        p = expit(np.asarray(z).ravel())\n",
    "        return np.c_[1.0 - p, p]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X)[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "class LassoBootstrapEstimatorCurrent(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, feature_codes_all, coef_map,\n",
    "                 dv_code,                      # <-- add this\n",
    "                 rank=\"prevalence\", n_frac=0.10, require_present=True,\n",
    "                 min_total_count=1, min_pos_carriers=0,\n",
    "                 C=0.5, max_iter=2000, n_jobs=-1, random_state=42,\n",
    "                 verbose=False):\n",
    "        self.feature_codes_all = feature_codes_all\n",
    "        self.coef_map = coef_map\n",
    "        self.dv_code = dv_code               # <-- store it\n",
    "        self.rank = rank\n",
    "        self.n_frac = n_frac\n",
    "        self.require_present = require_present\n",
    "        self.min_total_count = min_total_count\n",
    "        self.min_pos_carriers = min_pos_carriers\n",
    "        self.C = C\n",
    "        self.max_iter = max_iter\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self._feats_used = None\n",
    "        self._feature_codes_all = None\n",
    "        self._model = None\n",
    "        self._p_const = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feature_codes_all = np.asarray(self.feature_codes_all)\n",
    "        coef_map = dict(self.coef_map)\n",
    "\n",
    "        # selection with DV removed + EPV target 9, SAFE [5,9]\n",
    "        X_used, feats_used, _, _ = select_and_trim_to_epv_range(\n",
    "            X, y, feature_codes_all, coef_map,\n",
    "            dv_code=self.dv_code,                 # <-- pass dv_code\n",
    "            rank=self.rank, require_present=self.require_present,\n",
    "            epv_target=EPV_TARGET, epv_min=EPV_MIN,\n",
    "            min_total_count=MIN_TOTAL_COUNT, min_pos_carriers=MIN_POS_CARRIERS,             \n",
    "            verbose=self.verbose\n",
    "        )\n",
    "        assert self.dv_code not in set(feats_used), \"DV leaked into predictors! (LASSO)\"\n",
    "\n",
    "        if X_used.shape[1] == 0:\n",
    "            self._feats_used = np.array([], dtype=str)\n",
    "            self._feature_codes_all = feature_codes_all\n",
    "            self._model = None\n",
    "            self._p_const = float(np.mean(y))\n",
    "            return self\n",
    "\n",
    "        self._feats_used = feats_used\n",
    "        self._feature_codes_all = feature_codes_all\n",
    "\n",
    "        self._model = LogisticRegression(\n",
    "            penalty=\"l1\", solver=\"saga\", C=self.C,\n",
    "            max_iter=self.max_iter, n_jobs=self.n_jobs,\n",
    "            random_state=self.random_state\n",
    "        ).fit(X_used, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self._feats_used is None or self._feats_used.size == 0 or self._model is None:\n",
    "            p = np.full(X.shape[0], self._p_const if self._p_const is not None else 0.5, dtype=float)\n",
    "            return np.c_[1.0 - p, p]\n",
    "        code_to_idx = {c: i for i, c in enumerate(self._feature_codes_all)}\n",
    "        col_idx = np.array([code_to_idx[c] for c in self._feats_used], dtype=int)\n",
    "        p = self._model.predict_proba(X[:, col_idx])[:, 1]\n",
    "        return np.c_[1.0 - p, p]\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self._feats_used is None or self._feats_used.size == 0 or self._model is None:\n",
    "            p = self._p_const if self._p_const is not None else 0.5\n",
    "            return (np.full(X.shape[0], p) >= 0.5).astype(int)\n",
    "        code_to_idx = {c: i for i, c in enumerate(self._feature_codes_all)}\n",
    "        col_idx = np.array([code_to_idx[c] for c in self._feats_used], dtype=int)\n",
    "        proba = self._model.predict_proba(X[:, col_idx])[:, 1]\n",
    "        return (proba >= 0.5).astype(int)\n",
    "\n",
    "# -------------------- LOAD DESIGN --------------------\n",
    "banner(\"LOAD DESIGN\")\n",
    "X_full  = load_npz(f\"{BASE}/Lasso_X.npz\").tocsr().astype(np.float32)\n",
    "persons = pd.read_csv(f\"{BASE}/person_index.csv\")[\"person_id\"].astype(str).to_numpy()\n",
    "codes   = pd.read_csv(f\"{BASE}/code_index.csv\")[\"concept_code\"].astype(str).to_numpy()\n",
    "print(f\"[INFO] Matrix: persons={X_full.shape[0]:,}  codes={X_full.shape[1]:,}\")\n",
    "if len(persons) != X_full.shape[0] or len(codes) != X_full.shape[1]:\n",
    "    raise ValueError(\"[ERROR] person/code indices do not match matrix shape.\")\n",
    "\n",
    "# -------------------- RUN PER TARGET --------------------\n",
    "rows = []\n",
    "for tcode, pretty in TARGET_NAME.items():\n",
    "    safe = safe_name(pretty)\n",
    "    banner(f\"TARGET {tcode} — {pretty}\")\n",
    "\n",
    "    # A) Labels\n",
    "    idx_y = np.where(codes == tcode)[0]\n",
    "    if idx_y.size == 0:\n",
    "        print(f\"[SKIP] Target not found in code_index.csv → {tcode}\")\n",
    "        continue\n",
    "    y_full = X_full[:, idx_y[0]].toarray().ravel().astype(np.int8)\n",
    "\n",
    "    # B) Predictors (exclude DV)\n",
    "    mask_pred = (codes != tcode)\n",
    "    X = X_full[:, mask_pred]\n",
    "    feature_codes = codes[mask_pred]\n",
    "\n",
    "    # C) Sample: include all cases + 4× controls\n",
    "    sel = sample_fixed_pos_neg(y_full, n_pos=None, seed=RNG_SEED)\n",
    "    X_sub = X[sel, :].tocsr().astype(np.float32)\n",
    "    y_sub = y_full[sel].astype(int).ravel()\n",
    "    persons_sub = persons[sel]\n",
    "\n",
    "    n_rows = X_sub.shape[0]\n",
    "    n_pos  = int(y_sub.sum())\n",
    "    n_neg  = int(n_rows - n_pos)\n",
    "    print(f\"[INFO] subset: n={n_rows:,}  pos={n_pos:,}  neg={n_neg:,}  baseline={y_sub.mean():.4f}\")\n",
    "\n",
    "    # D) Load MAGI coefs\n",
    "    coef_csv = COEF_PATTERN.format(target=tcode)\n",
    "    if not os.path.exists(coef_csv):\n",
    "        print(f\"[SKIP] Missing MAGI coef file: {coef_csv}\")\n",
    "        continue\n",
    "    intercept, coef_map = load_magi_betas(coef_csv)\n",
    "    print(f\"[INFO] MAGI coefs: intercept={intercept:.6f}  n_features={len(coef_map):,}\")\n",
    "\n",
    "    # E) Selection per NEW EPV rules (EPV≈9, then SAFE to [5,9])\n",
    "    X_used, feats_used, _, epv = select_and_trim_to_epv_range(\n",
    "        X_sub, y_sub, feature_codes, coef_map, dv_code=tcode,\n",
    "        rank=RANK_MODE, require_present=True, \n",
    "        # default SAFE presence (mild) before any additional tightening:\n",
    "        min_total_count=MIN_TOTAL_COUNT, min_pos_carriers=MIN_POS_CARRIERS,\n",
    "        epv_target=EPV_TARGET, epv_min=EPV_MIN, verbose=False\n",
    "    )\n",
    "    print(f\"[INFO] Predictors kept={X_used.shape[1]}  EPV={epv:.3f}\")\n",
    "\n",
    "    # If EPV still <5 → trim was applied inside; if EPV >9 due to limited MAGI features, we keep and log.\n",
    "    if epv > 9.0:\n",
    "        print(\"[NOTE] EPV > 9 (few MAGI features available). Proceeding with simpler model (no fill).\")\n",
    "    \n",
    "    assert tcode not in set(feats_used), \"DV leaked into predictors!\"\n",
    "    \n",
    "        \n",
    "    # inside the loop, right after selection:\n",
    "    n_min = int(np.ceil(n_pos / EPV_TARGET))\n",
    "    n_max = max(n_min, int(np.floor(n_pos / EPV_MIN)))\n",
    "    print(f\"[INFO] n_pos={n_pos}  n_min(pref@EPV≈{EPV_TARGET})={n_min}  \"\n",
    "          f\"n_max(EPV≥{EPV_MIN})={n_max}  kept={X_used.shape[1]}  EPV={epv:.3f}\")\n",
    "\n",
    "    # ---- MAGI: same features ----\n",
    "    if X_used.shape[1] == 0:\n",
    "        p_hat_magi = np.full(n_rows, float(expit(intercept)), dtype=float)\n",
    "        magi_nz_feats = np.array([], dtype=str)\n",
    "        magi_nz_betas = np.array([], dtype=float)\n",
    "    else:\n",
    "        betas_vec = np.array([coef_map.get(f, 0.0) for f in feats_used], dtype=float)\n",
    "        lp = intercept + X_used.dot(betas_vec)\n",
    "        p_hat_magi = expit(np.asarray(lp).ravel())\n",
    "        nz_mask = betas_vec != 0\n",
    "        magi_nz_feats = np.array(feats_used)[nz_mask]\n",
    "        magi_nz_betas = betas_vec[nz_mask]\n",
    "    print(f\"[MAGI] #non-zero features: {magi_nz_feats.size}\")\n",
    "    if magi_nz_feats.size:\n",
    "        pairs = sorted(zip(magi_nz_feats.tolist(), magi_nz_betas.tolist()),\n",
    "                       key=lambda x: abs(x[1]), reverse=True)\n",
    "        print(\"[MAGI] Non-zero features (sorted by |beta|):\")\n",
    "        for name, val in pairs:\n",
    "            print(f\"   {name:>40}  {val:+.6f}\")\n",
    "    else:\n",
    "        print(\"[MAGI] No non-zero features (intercept-only).\")\n",
    "\n",
    "    auc_magi = roc_auc_score(y_sub, p_hat_magi)\n",
    "    print(f\"[RESULT] MAGI  AUC={auc_magi:.4f}  baseline={y_sub.mean():.4f}\")\n",
    "\n",
    "    # Save MAGI used coefs\n",
    "    magi_used_df = pd.DataFrame({\"feature\": magi_nz_feats, \"beta\": magi_nz_betas})\n",
    "    magi_used_df.loc[-1] = {\"feature\": \"(intercept)\", \"beta\": float(intercept)}\n",
    "    magi_used_df.index = magi_used_df.index + 1\n",
    "    magi_used_csv = os.path.join(OUT_DIR, f\"magi_coef_used_{safe}.csv\")\n",
    "    magi_used_df.to_csv(magi_used_csv, index=False)\n",
    "\n",
    "    # MAGI preds & ROC\n",
    "    pred_csv_magi = os.path.join(CSV_DIR, f\"pred_{safe}.csv\")\n",
    "    pd.DataFrame({\"person_id\": persons_sub, \"y_true\": y_sub.astype(int), \"prob_magi\": p_hat_magi}).to_csv(pred_csv_magi, index=False)\n",
    "    png_path = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}.png\"))\n",
    "    svg_path = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}.svg\"))\n",
    "    plot_roc(y_sub, p_hat_magi, pretty, png_path, svg_path)\n",
    "    \n",
    "    # ---- LASSO on SAME features (5-fold CV) ----\n",
    "    try:\n",
    "        if X_used.shape[1] == 0:\n",
    "            print(\"[SKIP] No usable features; LASSO fallback to constant.\")\n",
    "            lasso_cv_auc = np.nan; lasso_auc = np.nan\n",
    "            p_hat_lasso = np.full(n_rows, float(y_sub.mean()), dtype=float)\n",
    "            lasso_pred_csv = \"\"; lasso_coef_csv = \"\"\n",
    "        else:\n",
    "            clf = LogisticRegressionCV(\n",
    "                Cs=np.logspace(-3, 3, 12),\n",
    "                cv=5,\n",
    "                penalty=\"l1\",\n",
    "                solver=\"saga\",\n",
    "                scoring=\"roc_auc\",\n",
    "                max_iter=2000,\n",
    "                n_jobs=-1,\n",
    "                random_state=RNG_SEED,\n",
    "                refit=True,\n",
    "                fit_intercept=True,\n",
    "            ).fit(X_used, y_sub)\n",
    "\n",
    "            scores_mat = clf.scores_[1]\n",
    "            mean_auc_per_C = scores_mat.mean(axis=0)\n",
    "            best_idx = int(np.argmax(mean_auc_per_C))\n",
    "            lasso_cv_auc = float(mean_auc_per_C[best_idx])\n",
    "            best_C = float(np.atleast_1d(clf.C_)[0])\n",
    "            print(f\"[MODEL] LASSO best_C={best_C:.6g}  CV-AUC={lasso_cv_auc:.4f}\")\n",
    "\n",
    "            p_hat_lasso = clf.predict_proba(X_used)[:, 1]\n",
    "            lasso_auc   = roc_auc_score(y_sub, p_hat_lasso)\n",
    "            print(f\"[RESULT] LASSO AUC={lasso_auc:.4f}  baseline={y_sub.mean():.4f}\")\n",
    "\n",
    "            # Save preds / coefs\n",
    "            lasso_pred_csv = os.path.join(CSV_DIR, f\"pred_{safe}_LASSO.csv\")\n",
    "            pd.DataFrame({\"person_id\": persons_sub, \"y_true\": y_sub.astype(int), \"prob_lasso\": p_hat_lasso}).to_csv(lasso_pred_csv, index=False)\n",
    "\n",
    "            coef = clf.coef_.ravel(); intercept_l = float(clf.intercept_.ravel()[0])\n",
    "            nz = np.where(coef != 0)[0]\n",
    "            coef_df = (pd.DataFrame({\"feature\": np.array(feats_used)[nz], \"coef\": coef[nz]})\n",
    "                       .sort_values(\"coef\", key=np.abs, ascending=False))\n",
    "            coef_df.loc[-1] = {\"feature\": \"(intercept)\", \"coef\": intercept_l}\n",
    "            coef_df.index = coef_df.index + 1\n",
    "            lasso_coef_csv = os.path.join(OUT_DIR, f\"lasso_coef_{safe}.csv\")\n",
    "            coef_df.to_csv(lasso_coef_csv, index=False)\n",
    "            print(f\"[LASSO] #non-zero features: {nz.size}\")\n",
    "            if nz.size:\n",
    "                rows_print = [(str(feats_used[i]), float(coef[i])) for i in nz]\n",
    "                rows_print.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "                print(\"[LASSO] Non-zero features (sorted by |coef|):\")\n",
    "                for name, val in rows_print:\n",
    "                    print(f\"   {name:>40}  {val:+.6f}\")\n",
    "            else:\n",
    "                print(\"[LASSO] No non-zero coefficients (all zero)\")\n",
    "            print(f\"[LASSO] Intercept: {intercept_l:+.6f}\")\n",
    "\n",
    "            lasso_roc_png = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}_LASSO.png\"))\n",
    "            lasso_roc_svg = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}_LASSO.svg\"))\n",
    "            plot_roc(y_sub, p_hat_lasso, f\"{pretty} (LASSO, CV=5)\", lasso_roc_png, lasso_roc_svg)\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] LASSO failed: {e}\")\n",
    "        lasso_cv_auc = np.nan; lasso_auc = np.nan\n",
    "        lasso_pred_csv = \"\"; lasso_coef_csv = \"\"\n",
    "        p_hat_lasso = np.full(n_rows, float(y_sub.mean()), dtype=float)\n",
    "        \n",
    "    # ---- Bootstrap policy: run if EPV is not too large relative to target ----\n",
    "    run_bootstrap = (epv <= BOOTSTRAP_EPV_MAX_MULTIPLIER * EPV_TARGET) and (X_used.shape[1] > 0)\n",
    "    AUC632_MAGI_mean = AUC632_MAGI_std = np.nan\n",
    "    AUC632_LASSO_mean = AUC632_LASSO_std = np.nan\n",
    "    ACC632_MAGI_mean = ACC632_MAGI_std = np.nan\n",
    "    ACC632_LASSO_mean = ACC632_LASSO_std = np.nan\n",
    "\n",
    "    if run_bootstrap:\n",
    "        magi_est = MagiBootstrapEstimatorCurrent(\n",
    "            intercept=intercept, coef_map=coef_map, feature_codes_all=feature_codes, dv_code=tcode,  \n",
    "            rank=RANK_MODE, min_total_count=MIN_TOTAL_COUNT, min_pos_carriers=MIN_POS_CARRIERS, verbose=False\n",
    "        )\n",
    "        lasso_est = LassoBootstrapEstimatorCurrent(\n",
    "            feature_codes_all=feature_codes, coef_map=coef_map, dv_code=tcode,  \n",
    "            rank=RANK_MODE, min_total_count=MIN_TOTAL_COUNT, min_pos_carriers=MIN_POS_CARRIERS,\n",
    "            C=0.5, max_iter=2000, n_jobs=-1, random_state=RNG_SEED, verbose=False\n",
    "        )\n",
    "        try:\n",
    "            auc632_magi  = bootstrap_632plus_or_fallback(\n",
    "                magi_est, X_sub, y_sub, N_BOOT, roc_auc_score, True, RNG_SEED, clone_estimator=False\n",
    "            )\n",
    "            auc632_lasso = bootstrap_632plus_or_fallback(\n",
    "                lasso_est, X_sub, y_sub, N_BOOT, roc_auc_score, True, RNG_SEED, clone_estimator=False\n",
    "            )\n",
    "            acc632_magi  = bootstrap_632plus_or_fallback(\n",
    "                magi_est, X_sub, y_sub, N_BOOT, accuracy_score, False, RNG_SEED, clone_estimator=False\n",
    "            )\n",
    "            acc632_lasso = bootstrap_632plus_or_fallback(\n",
    "                lasso_est, X_sub, y_sub, N_BOOT, accuracy_score, False, RNG_SEED, clone_estimator=False\n",
    "            )\n",
    "            AUC632_MAGI_mean = float(np.mean(auc632_magi));  AUC632_MAGI_std  = float(np.std(auc632_magi))\n",
    "            AUC632_LASSO_mean = float(np.mean(auc632_lasso));AUC632_LASSO_std = float(np.std(auc632_lasso))\n",
    "            ACC632_MAGI_mean = float(np.mean(acc632_magi));  ACC632_MAGI_std  = float(np.std(acc632_magi))\n",
    "            ACC632_LASSO_mean = float(np.mean(acc632_lasso));ACC632_LASSO_std = float(np.std(acc632_lasso))\n",
    "            print(f\"[BOOT] MAGI  .632+ AUC: mean={AUC632_MAGI_mean:.4f}  std={AUC632_MAGI_std:.4f}\")\n",
    "            print(f\"[BOOT] LASSO .632+ AUC: mean={AUC632_LASSO_mean:.4f} std={AUC632_LASSO_std:.4f}\")\n",
    "            print(f\"[BOOT] MAGI  .632+ ACC: mean={ACC632_MAGI_mean:.4f}  std={ACC632_MAGI_std:.4f}\")\n",
    "            print(f\"[BOOT] LASSO .632+ ACC: mean={ACC632_LASSO_mean:.4f} std={ACC632_LASSO_std:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Bootstrap failed for {tcode}: {e}\")\n",
    "    else:\n",
    "        if X_used.shape[1] == 0:\n",
    "            print(\"[VAL] No predictors kept; skipping bootstrap.\")\n",
    "        else:\n",
    "            thr = BOOTSTRAP_EPV_MAX_MULTIPLIER * EPV_TARGET\n",
    "            print(f\"[VAL] EPV > {thr:.1f}: per spec, bootstrap not required; skipping.\")\n",
    "\n",
    "    # ---- Summary row ---------------------------------------------------------\n",
    "    rows.append({\n",
    "        \"target_code\": tcode,\n",
    "        \"target_name\": pretty,\n",
    "        \"n_cases\": int(n_rows),\n",
    "        \"n_pos\": int(n_pos),\n",
    "        \"n_neg\": int(n_neg),\n",
    "        \"rank_mode\": RANK_MODE,\n",
    "        \"features_used\": int(X_used.shape[1]),\n",
    "        \"EPV\": float(epv),\n",
    "        \"magi_nonzero_count\": int(magi_nz_feats.size),\n",
    "        \"lasso_nonzero_count\": int(nz.size) if 'nz' in locals() else 0,\n",
    "        \"AUC_MAGI\": float(auc_magi),\n",
    "        \"AUC_LASSO\": float(lasso_auc) if 'lasso_auc' in locals() and not np.isnan(lasso_auc) else np.nan,\n",
    "        \"AUC632_MAGI_mean\":  AUC632_MAGI_mean,\n",
    "        \"AUC632_MAGI_std\":   AUC632_MAGI_std,\n",
    "        \"AUC632_LASSO_mean\": AUC632_LASSO_mean,\n",
    "        \"AUC632_LASSO_std\":  AUC632_LASSO_std,\n",
    "        \"ACC632_MAGI_mean\":  ACC632_MAGI_mean,\n",
    "        \"ACC632_MAGI_std\":   ACC632_MAGI_std,\n",
    "        \"ACC632_LASSO_mean\": ACC632_LASSO_mean,\n",
    "        \"ACC632_LASSO_std\":  ACC632_LASSO_std,\n",
    "        \"coef_csv\": coef_csv,\n",
    "        \"magi_used_coef_csv\": os.path.join(OUT_DIR, f\"magi_coef_used_{safe}.csv\"),\n",
    "        \"pred_csv_MAGI\": os.path.join(CSV_DIR, f\"pred_{safe}.csv\"),\n",
    "        \"pred_csv_LASSO\": os.path.join(CSV_DIR, f\"pred_{safe}_LASSO.csv\") if 'lasso_pred_csv' in locals() else \"\",\n",
    "        \"lasso_coef_csv\": os.path.join(OUT_DIR, f\"lasso_coef_{safe}.csv\") if 'lasso_coef_csv' in locals() else \"\",\n",
    "        \"roc_png_MAGI\": os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}.png\")),\n",
    "        \"roc_png_LASSO\": os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}_LASSO.png\")) if 'lasso_roc_png' in locals() else \"\",\n",
    "    })\n",
    "\n",
    "# -------------------- SAVE SUMMARY --------------------\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(SUMMARY_CSV, index=False)\n",
    "    # After you build `rows` (or right after selection), do something like:\n",
    "    n_pos_local = int(y_sub.sum())\n",
    "    n_min = max(1, int(np.ceil(n_pos_local / float(EPV_TARGET))))\n",
    "    n_max = max(n_min, int(np.floor(n_pos_local / float(EPV_MIN))))\n",
    "    print(f\"[INFO] n_pos={n_pos_local}  \"\n",
    "          f\"n_min(pref@EPV≈{EPV_TARGET})={n_min}  n_max(EPV≥{EPV_MIN})={n_max}  \"\n",
    "          f\"kept={X_used.shape[1]}  EPV={epv:.3f}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n[SUMMARY] Nothing to save.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
