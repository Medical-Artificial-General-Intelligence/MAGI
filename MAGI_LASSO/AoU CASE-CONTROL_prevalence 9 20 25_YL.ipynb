{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==========================================================\n",
    "# MAGI vs LASSO with Top (ceil(n_patients / 10)) Features\n",
    "# - Loads MAGI coefficients\n",
    "# - Samples up to 1,000 positives + 4× negatives (or all pos if <1000, neg=4×pos)\n",
    "# - Selects top-N features by prevalence in the SAMPLE (N = ceil(n_rows/10)),\n",
    "#   prioritizing MAGI-coefficient features to ensure overlap when possible\n",
    "# - Scores MAGI (intercept-only fallback) and fits LASSO (5-fold CV)\n",
    "# - Saves single ROCs and a combined ROC overlay (MAGI vs LASSO)\n",
    "# - Always writes a summary CSV row per target\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.special import expit\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, auc as auc_area\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- UTILS ----------\n",
    "def banner(txt):\n",
    "    bar = \"=\" * max(12, len(txt) + 4)\n",
    "    print(f\"\\n{bar}\\n{txt}\\n{bar}\")\n",
    "\n",
    "def subhead(txt):\n",
    "    print(f\"\\n--- {txt} ---\")\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    return \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\") else \"_\" for ch in s)\n",
    "\n",
    "def qtiles(x):\n",
    "    x = np.asarray(x)\n",
    "    return np.quantile(x, [0, 0.01, 0.25, 0.5, 0.75, 0.99, 1.0])\n",
    "\n",
    "def preview_active_codes(X_csr, feature_codes, row_indices, k=8):\n",
    "    for i in row_indices:\n",
    "        start, end = X_csr.indptr[i], X_csr.indptr[i+1]\n",
    "        cols = X_csr.indices[start:end]\n",
    "        codes_list = [feature_codes[j] for j in cols[:k]]\n",
    "        print(f\"   row {i}: n_active={len(cols)}  sample_active={codes_list}\")\n",
    "\n",
    "def warn_if_exceeds_cap(n_used: int, n_rows: int, label: str = \"features\"):\n",
    "    cap = int(np.ceil(n_rows / 10.0))\n",
    "    if n_used > cap:\n",
    "        print(f\"[WARN] {label}: {n_used} > 1/10 of cases ({cap}). \"\n",
    "              f\"Consider tightening selection or thresholds.\")\n",
    "    return cap\n",
    "\n",
    "def load_magi_betas(coef_csv):\n",
    "    df = pd.read_csv(coef_csv)\n",
    "    def pick(df, opts):\n",
    "        for c in opts:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        raise KeyError(f\"Missing any of {opts} in {coef_csv}. Found: {list(df.columns)}\")\n",
    "    code_col = pick(df, [\"concept_code\",\"standard_concept_code\",\"predictor\",\"feature\",\"term\",\"name\"])\n",
    "    beta_col = pick(df, [\"coef\",\"coefficient\",\"beta\",\"estimate\",\"b\",\"value\"])\n",
    "    df[code_col] = df[code_col].astype(str).str.strip()\n",
    "    is_int = df[code_col].str.lower().isin([\"(intercept)\",\"intercept\",\"const\",\"(const)\",\"bias\"])\n",
    "    intercept = float(df.loc[is_int, beta_col].iloc[0]) if is_int.any() else 0.0\n",
    "    coef_map  = dict(zip(df.loc[~is_int, code_col], df.loc[~is_int, beta_col].astype(float)))\n",
    "    return intercept, coef_map\n",
    "\n",
    "def sample_fixed_pos_neg(y, n_pos=1000, seed=42):\n",
    "    \"\"\"\n",
    "    If <1000 positives, take ALL positives, then take 4× as many negatives\n",
    "    (capped by availability). Same as your intent.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pos_idx = np.where(y == 1)[0]\n",
    "    neg_idx = np.where(y == 0)[0]\n",
    "    if pos_idx.size == 0:\n",
    "        raise ValueError(\"No positives for this target.\")\n",
    "\n",
    "    take_pos = min(n_pos, pos_idx.size)\n",
    "    take_neg = min(4 * take_pos, neg_idx.size)\n",
    "\n",
    "    sel_pos = rng.choice(pos_idx, size=take_pos, replace=False)\n",
    "    sel_neg = rng.choice(neg_idx, size=take_neg, replace=False)\n",
    "    sel = np.concatenate([sel_pos, sel_neg])\n",
    "    rng.shuffle(sel)\n",
    "    return sel\n",
    "\n",
    "def drop_constants_and_duplicates_for_sample(X_csr, feature_codes):\n",
    "    n_rows, n_cols = X_csr.shape\n",
    "    nnz = np.asarray((X_csr != 0).sum(axis=0)).ravel()\n",
    "    keep_mask = (nnz > 0)\n",
    "\n",
    "    X_csc = X_csr[:, keep_mask].tocsc()\n",
    "    sub_keep = np.ones(X_csc.shape[1], dtype=bool)\n",
    "    seen = {}\n",
    "    for j in range(X_csc.shape[1]):\n",
    "        s, e = X_csc.indptr[j], X_csc.indptr[j+1]\n",
    "        idx = X_csc.indices[s:e]\n",
    "        dat = X_csc.data[s:e]\n",
    "        key = (idx.tobytes(), dat.tobytes())\n",
    "        if key in seen:\n",
    "            sub_keep[j] = False\n",
    "        else:\n",
    "            seen[key] = j\n",
    "\n",
    "    keep_idx = np.where(keep_mask)[0]\n",
    "    keep_mask_final = np.zeros(n_cols, dtype=bool)\n",
    "    keep_mask_final[keep_idx[sub_keep]] = True\n",
    "\n",
    "    X_red = X_csr[:, keep_mask_final]\n",
    "    feats_red = feature_codes[keep_mask_final]\n",
    "    dropped = n_cols - int(keep_mask_final.sum())\n",
    "    print(f\"[INFO] LASSO collinearity cleanup: kept {X_red.shape[1]:,}/{n_cols:,} features \"\n",
    "          f\"(dropped {dropped:,} all-zero/duplicate).\")\n",
    "    return X_red, feats_red, keep_mask_final\n",
    "\n",
    "def select_features_current_policy(\n",
    "    X_train, y_train, feature_codes, coef_map,\n",
    "    n_keep, rank=\"beta\", require_present=True,\n",
    "    min_total_count=1, min_pos_carriers=0, verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Matches your current C2 path:\n",
    "      - MAGI-only (codes present in coef_map), NO FILL\n",
    "      - Optionally require presence on TRAIN split\n",
    "      - Rank by |beta| (default) or by TRAIN prevalence\n",
    "      - Keep up to n_keep (ceil(n_train/10) upstream), fewer if not enough\n",
    "\n",
    "    Returns keep_idx (absolute col indices w.r.t. X_train/feature_codes).\n",
    "    \"\"\"\n",
    "    # MAGI mapping across ALL predictor columns\n",
    "    mapped_mask = np.array([c in coef_map for c in feature_codes], dtype=bool)\n",
    "    cand_idx = np.where(mapped_mask)[0]\n",
    "    if cand_idx.size == 0:\n",
    "        if verbose: print(\"[SEL] No MAGI-mapped features available.\")\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    # Presence/support checks on TRAIN\n",
    "    if require_present or (min_total_count > 1) or (min_pos_carriers > 0):\n",
    "        nnz_all = np.asarray((X_train != 0).sum(axis=0)).ravel()  # per-column\n",
    "        keep = mapped_mask.copy()\n",
    "        if require_present:\n",
    "            keep &= (nnz_all >= max(1, min_total_count))\n",
    "        if min_pos_carriers > 0 and y_train is not None and y_train.any():\n",
    "            pos_rows = np.where(y_train == 1)[0]\n",
    "            nnz_pos = np.asarray((X_train[pos_rows, :] != 0).sum(axis=0)).ravel()\n",
    "            keep &= (nnz_pos >= min_pos_carriers)\n",
    "        cand_idx = np.where(keep)[0]\n",
    "        if cand_idx.size == 0:\n",
    "            if verbose: print(\"[SEL] After presence/support filters, no features remain.\")\n",
    "            return np.array([], dtype=int)\n",
    "\n",
    "    # Ranking\n",
    "    if rank == \"prevalence\":\n",
    "        nnz = np.asarray((X_train != 0).sum(axis=0)).ravel()\n",
    "        order = cand_idx[np.argsort(-nnz[cand_idx])]  # DESC by TRAIN prevalence\n",
    "    elif rank == \"beta\":\n",
    "        betas = np.array([coef_map[feature_codes[i]] for i in cand_idx], dtype=float)\n",
    "        order = cand_idx[np.argsort(-np.abs(betas))]  # DESC by |β|\n",
    "    else:\n",
    "        raise ValueError(\"rank must be 'beta' or 'prevalence'\")\n",
    "\n",
    "    keep_idx = order[:min(n_keep, order.size)]\n",
    "    if verbose:\n",
    "        print(f\"[SEL] MAGI cand={order.size:,}  keep_idx={keep_idx.size:,}  n_keep={n_keep}\")\n",
    "    return keep_idx\n",
    "\n",
    "# --- NEW: build top-N by prevalence, prioritizing MAGI features to ensure overlap when possible\n",
    "def build_topN_with_magi_overlap(X_sub, feature_codes, coef_map, n_keep):\n",
    "    \"\"\"\n",
    "    1) Rank all sample features by prevalence (non-zero counts).\n",
    "    2) Take as many MAGI-supported features (present in sample) as possible first.\n",
    "    3) If fewer than n_keep, fill with highest-prevalence non-MAGI features.\n",
    "    Returns X_top, feats_top, chosen_idx, n_magi_overlap\n",
    "    \"\"\"\n",
    "    nnz_all = np.asarray((X_sub != 0).sum(axis=0)).ravel()\n",
    "    order_all = np.argsort(-nnz_all)  # descending by prevalence\n",
    "\n",
    "    coef_keys = np.array(list(coef_map.keys()), dtype=str)\n",
    "    is_coef = np.isin(feature_codes, coef_keys)\n",
    "\n",
    "    # MAGI-supported features present in sample, ordered by prevalence\n",
    "    coef_order = order_all[is_coef[order_all]]\n",
    "    chosen = list(coef_order[:n_keep])\n",
    "\n",
    "    # fill remainder with top non-MAGI features\n",
    "    if len(chosen) < n_keep:\n",
    "        noncoef_order = order_all[~is_coef[order_all]]\n",
    "        fill_needed = n_keep - len(chosen)\n",
    "        chosen.extend(list(noncoef_order[:fill_needed]))\n",
    "\n",
    "    chosen = np.array(chosen, dtype=int)\n",
    "    X_top = X_sub[:, chosen]\n",
    "    feats_top = feature_codes[chosen]\n",
    "    n_magi_overlap = int(np.isin(feats_top, coef_keys).sum())\n",
    "    return X_top, feats_top, chosen, n_magi_overlap\n",
    "\n",
    "# --- Single-model ROC (bold axes; no title)\n",
    "def plot_roc(y_true, p_hat, title, out_png, out_svg):\n",
    "    fpr, tpr, _ = roc_curve(y_true, p_hat)\n",
    "    auc_val = roc_auc_score(y_true, p_hat)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={auc_val:.3f}\")\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\", linewidth=1)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.ylabel(\"True Positive Rate\",  fontsize=16, fontweight=\"bold\")\n",
    "    plt.xticks(fontsize=14, fontweight=\"bold\")\n",
    "    plt.yticks(fontsize=14, fontweight=\"bold\")\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.4)\n",
    "    plt.legend(loc=\"lower right\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(out_svg, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return float(auc_val)\n",
    "\n",
    "# --- NEW: Dual ROC (MAGI vs LASSO)\n",
    "def plot_roc_dual(y_true, p1, p2, label1, label2, out_png, out_svg):\n",
    "    fpr1, tpr1, _ = roc_curve(y_true, p1)\n",
    "    fpr2, tpr2, _ = roc_curve(y_true, p2)\n",
    "    auc1 = roc_auc_score(y_true, p1)\n",
    "    auc2 = roc_auc_score(y_true, p2)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr1, tpr1, label=f\"{label1} (AUC={auc1:.3f})\")\n",
    "    plt.plot(fpr2, tpr2, label=f\"{label2} (AUC={auc2:.3f})\")\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\", linewidth=1)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.ylabel(\"True Positive Rate\",  fontsize=16, fontweight=\"bold\")\n",
    "    plt.xticks(fontsize=14, fontweight=\"bold\")\n",
    "    plt.yticks(fontsize=14, fontweight=\"bold\")\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.4)\n",
    "    plt.legend(loc=\"lower right\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(out_svg, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return float(auc1), float(auc2)\n",
    "\n",
    "# ---------- LOAD DESIGN ----------\n",
    "banner(\"LOAD DESIGN\")\n",
    "X_full  = load_npz(f\"{BASE}/Lasso_X.npz\").tocsr().astype(np.float32)\n",
    "persons = pd.read_csv(f\"{BASE}/person_index.csv\")[\"person_id\"].astype(str).to_numpy()\n",
    "codes   = pd.read_csv(f\"{BASE}/code_index.csv\")[\"concept_code\"].astype(str).to_numpy()\n",
    "print(f\"[INFO] Matrix: persons={X_full.shape[0]:,}  codes={X_full.shape[1]:,}\")\n",
    "if len(persons) != X_full.shape[0] or len(codes) != X_full.shape[1]:\n",
    "    raise ValueError(\"[ERROR] person/code indices do not match matrix shape.\")\n",
    "\n",
    "# ---------- RUN PER TARGET ----------\n",
    "summary = []\n",
    "for tcode in TARGETS:\n",
    "    pretty = TARGET_NAME.get(tcode, tcode)\n",
    "    safe   = safe_name(pretty)  # define early so all sections can use it\n",
    "    banner(f\"TARGET {tcode} — {pretty}\")\n",
    "\n",
    "    # A) Labels\n",
    "    subhead(\"A) Label vector from full design\")\n",
    "    idx_y = np.where(codes == tcode)[0]\n",
    "    if idx_y.size == 0:\n",
    "        print(f\"[SKIP] Target not found in code_index.csv → {tcode}\")\n",
    "        continue\n",
    "    y_full = X_full[:, idx_y[0]].toarray().ravel().astype(np.int8)\n",
    "    print(f\"[INFO] y_full: n={y_full.size:,}  pos={int(y_full.sum()):,}  prev={y_full.mean():.4f}\")\n",
    "\n",
    "    # B) Predictors\n",
    "    subhead(\"B) Predictor matrix (keep all columns except DV)\")\n",
    "    mask_pred = (codes != tcode)\n",
    "    X = X_full[:, mask_pred]\n",
    "    feature_codes = codes[mask_pred]\n",
    "    print(f\"[INFO] Predictors: persons={X.shape[0]:,}  features={X.shape[1]:,}\")\n",
    "    print(f\"[CHECK] DV in features? {tcode in feature_codes} (should be False)\")\n",
    "\n",
    "    # C) Sampling rule: up to 1,000 pos; neg = 4×pos\n",
    "    subhead(\"C) Sampling (1,000 positives + 4× negatives)\")\n",
    "    sel = sample_fixed_pos_neg(y_full, n_pos=1000, seed=RNG_SEED)\n",
    "    X_sub       = X[sel, :]\n",
    "    y_sub       = y_full[sel].astype(np.int8)\n",
    "    persons_sub = persons[sel]\n",
    "    n_rows      = X_sub.shape[0]\n",
    "    n_pos_sub   = int(y_sub.sum()); n_neg_sub = n_rows - n_pos_sub\n",
    "    print(f\"[INFO] subset: n={n_rows:,}  pos={n_pos_sub:,}  neg={n_neg_sub:,}  \"\n",
    "          f\"ratio≈{(n_neg_sub/max(n_pos_sub,1)):.2f}:1  PR-baseline={y_sub.mean():.4f}\")\n",
    "    try:\n",
    "        preview_active_codes(X_sub, feature_codes, row_indices=range(min(3, n_rows)), k=8)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] preview_active_codes failed: {e}\")\n",
    "\n",
    "    # D) Load MAGI coefficients (MUST be before C2; used to prioritize)\n",
    "    subhead(\"D) Load MAGI coefficients\")\n",
    "    coef_csv = COEF_PATTERN.format(target=tcode)\n",
    "    if not os.path.exists(coef_csv):\n",
    "        print(f\"[SKIP] Coef file missing: {coef_csv}\")\n",
    "        continue\n",
    "    intercept, coef_map = load_magi_betas(coef_csv)\n",
    "    print(f\"[INFO] Coefs: intercept={intercept:.6f}  n_features={len(coef_map):,}\")\n",
    "    for k,(cc,bb) in enumerate(list(coef_map.items())[:5]):\n",
    "        print(f\"   beta[{cc}] = {bb:.6f}\")\n",
    "\n",
    "    # C2) Pick N = ceil(n/10) by prevalence, prioritizing MAGI features\n",
    "    subhead(\"C2) Keep top ceil(n_patients/10) features (prioritize MAGI features)\")\n",
    "    N_keep = int(np.ceil(n_rows / 10.0))\n",
    "    X_top, feats_top, kept_idx, magi_in_top = build_topN_with_magi_overlap(\n",
    "        X_sub, feature_codes, coef_map, N_keep\n",
    "    )\n",
    "    print(f\"[INFO] Top-N features: kept {X_top.shape[1]} / {feature_codes.size} (N={N_keep}); \"\n",
    "          f\"MAGI features within top-N = {magi_in_top}\")\n",
    "\n",
    "    # C3) Cleanup once (drop all-zero/duplicates) — shared by MAGI & LASSO\n",
    "    X_used, feats_used, _ = drop_constants_and_duplicates_for_sample(\n",
    "        X_top.tocsr().astype(np.float32), feats_top\n",
    "    )\n",
    "    n_used = X_used.shape[1]\n",
    "    magi_keys = set(coef_map.keys())\n",
    "    n_magi_used = int(sum(f in magi_keys for f in feats_used))\n",
    "    print(f\"[INFO] Features after shared cleanup: {n_used} (of which MAGI={n_magi_used})\")\n",
    "    \n",
    "    cap_1of10 = warn_if_exceeds_cap(n_used, n_rows, label=\"Features after shared cleanup\")\n",
    "\n",
    "    # After C3:\n",
    "    magi_mask = np.array([f in coef_map for f in feats_used], dtype=bool)\n",
    "    X_used = X_used[:, magi_mask]\n",
    "    feats_used = feats_used[magi_mask]\n",
    "    print(f\"[INFO] Enforcing: {X_used.shape[1]} features remain\")\n",
    "\n",
    "    # E) Align & score (MAGI) — SAME cleaned features as LASSO\n",
    "    betas_vec = np.array([coef_map.get(f, 0.0) for f in feats_used], dtype=float)  # 0.0 for non-MAGI cols\n",
    "    lp = intercept + X_used.dot(betas_vec)\n",
    "    p_hat_magi = expit(np.asarray(lp).ravel())\n",
    "    auc_magi = roc_auc_score(y_sub, p_hat_magi)\n",
    "    print(f\"[RESULT] MAGI AUC={auc_magi:.4f} (baseline={y_sub.mean():.4f})\")\n",
    "\n",
    "    # E2) Save MAGI non-zero coefficients actually used (post-cleanup)\n",
    "    magi_nz_mask  = betas_vec != 0\n",
    "    magi_nz_feats = np.array(feats_used)[magi_nz_mask]\n",
    "    magi_nz_betas = betas_vec[magi_nz_mask]\n",
    "    magi_coef_used_df = (\n",
    "        pd.DataFrame({\"feature\": magi_nz_feats, \"beta\": magi_nz_betas})\n",
    "          .assign(abs_beta=lambda df: df[\"beta\"].abs())\n",
    "          .sort_values(\"abs_beta\", ascending=False)\n",
    "          .drop(columns=\"abs_beta\")\n",
    "    )\n",
    "    magi_coef_used_df.loc[-1] = {\"feature\": \"(intercept)\", \"beta\": float(intercept)}\n",
    "    magi_coef_used_df.index = magi_coef_used_df.index + 1\n",
    "    magi_used_csv = os.path.join(OUT_DIR, f\"magi_coef_used_{safe}.csv\")\n",
    "    magi_coef_used_df.to_csv(magi_used_csv, index=False)\n",
    "    print(f\"[SAVE] MAGI used coefficients → {magi_used_csv} \"\n",
    "          f\"(nonzero={magi_nz_feats.size} of {len(feats_used)})\")\n",
    "\n",
    "    # F) Distribution (optional)\n",
    "    subhead(\"F) Metrics & probability distribution (MAGI)\")\n",
    "    q = qtiles(p_hat_magi)\n",
    "    print(f\"[RESULT] MAGI AUC={auc_magi:.4f}  (baseline={y_sub.mean():.4f})\")\n",
    "    print(f\"[DIST] prob quantiles: min={q[0]:.4g}, p1={q[1]:.4g}, p25={q[2]:.4g}, \"\n",
    "          f\"median={q[3]:.4g}, p75={q[4]:.4g}, p99={q[5]:.4g}, max={q[6]:.4g}\")\n",
    "\n",
    "    # G) Save MAGI predictions\n",
    "    subhead(\"G) Save per-person predictions (MAGI)\")\n",
    "    pred_csv = os.path.join(CSV_DIR, f\"pred_{safe}.csv\")\n",
    "    pd.DataFrame({\"person_id\": persons_sub, \"y_true\": y_sub.astype(int), \"prob_magi\": p_hat_magi}).to_csv(pred_csv, index=False)\n",
    "    print(f\"[SAVE] predictions → {pred_csv}\")\n",
    "\n",
    "    # H) Single ROC (MAGI)\n",
    "    subhead(\"H) ROC plots (MAGI) PNG/SVG\")\n",
    "    png_path = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}.png\"))\n",
    "    svg_path = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}.svg\"))\n",
    "    _ = plot_roc(y_sub, p_hat_magi, pretty, png_path, svg_path)\n",
    "    print(f\"[SAVE] ROC → {png_path}\")\n",
    "    print(f\"[SAVE] ROC → {svg_path}\")\n",
    "\n",
    "    # I) LASSO: 5-fold CV on the SAME cleaned features (NO extra cleanup)\n",
    "    subhead(\"I) LASSO: 5-fold CV on SAME cleaned features\")\n",
    "    try:\n",
    "        if X_used.shape[1] == 0:\n",
    "            print(\"[SKIP] No usable features; LASSO fallback to constant.\")\n",
    "            lasso_cv_auc = np.nan; lasso_auc = np.nan\n",
    "            lasso_pred_csv = \"\"; lasso_coef_csv = \"\"\n",
    "            p_hat_lasso = np.full(n_rows, float(y_sub.mean()), dtype=float)\n",
    "        else:\n",
    "            clf = LogisticRegressionCV(\n",
    "                Cs=np.logspace(-3, 3, 12),\n",
    "                cv=5,\n",
    "                penalty=\"l1\",\n",
    "                solver=\"saga\",\n",
    "                scoring=\"roc_auc\",\n",
    "                max_iter=2000,\n",
    "                n_jobs=-1,\n",
    "                random_state=RNG_SEED,\n",
    "                refit=True,\n",
    "                fit_intercept=True,\n",
    "            ).fit(X_used, y_sub)\n",
    "\n",
    "            scores_mat = clf.scores_[1]\n",
    "            mean_auc_per_C = scores_mat.mean(axis=0)\n",
    "            best_idx = int(np.argmax(mean_auc_per_C))\n",
    "            lasso_cv_auc = float(mean_auc_per_C[best_idx])\n",
    "            best_C = float(np.atleast_1d(clf.C_)[0])\n",
    "            print(f\"[MODEL] LASSO best_C={best_C:.6g}  CV-AUC={lasso_cv_auc:.4f}\")\n",
    "\n",
    "            p_hat_lasso = clf.predict_proba(X_used)[:, 1]\n",
    "            lasso_auc   = roc_auc_score(y_sub, p_hat_lasso)\n",
    "            print(f\"[RESULT] LASSO Refit AUC={lasso_auc:.4f} (baseline={y_sub.mean():.4f})\")\n",
    "\n",
    "            # Save LASSO predictions\n",
    "            lasso_pred_csv = os.path.join(CSV_DIR, f\"pred_{safe}_LASSO.csv\")\n",
    "            pd.DataFrame({\"person_id\": persons_sub, \"y_true\": y_sub.astype(int), \"prob_lasso\": p_hat_lasso}).to_csv(lasso_pred_csv, index=False)\n",
    "            print(f\"[SAVE] LASSO predictions → {lasso_pred_csv}\")\n",
    "\n",
    "            # Save non-zero LASSO coefficients (aligned to feats_used)\n",
    "            coef = clf.coef_.ravel(); intercept_l = float(clf.intercept_.ravel()[0])\n",
    "            nz = np.where(coef != 0)[0]\n",
    "            coef_df = (pd.DataFrame({\"feature\": np.array(feats_used)[nz], \"coef\": coef[nz]})\n",
    "                       .sort_values(\"coef\", key=np.abs, ascending=False))\n",
    "            coef_df.loc[-1] = {\"feature\": \"(intercept)\", \"coef\": intercept_l}\n",
    "            coef_df.index = coef_df.index + 1\n",
    "            lasso_coef_csv = os.path.join(OUT_DIR, f\"lasso_coef_{safe}.csv\")\n",
    "            coef_df.to_csv(lasso_coef_csv, index=False)\n",
    "            print(f\"[SAVE] LASSO coefficients → {lasso_coef_csv} (nonzero={len(nz)} of {len(coef)})\")\n",
    "\n",
    "            # ROC (LASSO)\n",
    "            lasso_roc_png = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}_LASSO.png\"))\n",
    "            lasso_roc_svg = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}_LASSO.svg\"))\n",
    "            _ = plot_roc(y_sub, p_hat_lasso, f\"{pretty} (LASSO, CV=5)\", lasso_roc_png, lasso_roc_svg)\n",
    "            print(f\"[SAVE] LASSO ROC → {lasso_roc_png}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] LASSO failed: {e}\")\n",
    "        lasso_cv_auc = np.nan; lasso_auc = np.nan\n",
    "        lasso_pred_csv = \"\"; lasso_coef_csv = \"\"\n",
    "        p_hat_lasso = np.full(n_rows, float(y_sub.mean()), dtype=float)\n",
    "\n",
    "    # J) Combined ROC overlay (MAGI vs LASSO)\n",
    "    subhead(\"J) Combined ROC: MAGI vs LASSO (overlay)\")\n",
    "    dual_png = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}_MAGI_vs_LASSO.png\"))\n",
    "    dual_svg = os.path.abspath(os.path.join(PNG_DIR, f\"ROC_{safe}_MAGI_vs_LASSO.svg\"))\n",
    "    _ = plot_roc_dual(y_true=y_sub, p1=p_hat_magi, p2=p_hat_lasso,\n",
    "                      label1=\"MAGI\", label2=\"LASSO\",\n",
    "                      out_png=dual_png, out_svg=dual_svg)\n",
    "    print(f\"[SAVE] Dual ROC → {dual_png}\")\n",
    "\n",
    "    # Summary row\n",
    "    summary.append({\n",
    "        \"target_code\": tcode,\n",
    "        \"target_name\": pretty,\n",
    "        \"n_cases\": int(n_rows),\n",
    "        \"n_pos\": int(n_pos_sub),\n",
    "        \"n_neg\": int(n_neg_sub),\n",
    "        \"features_used\": int(n_used),\n",
    "        \"features_used_MAGI\": int(n_magi_used),\n",
    "        \"AUC_MAGI\": float(auc_magi),\n",
    "        \"PR_baseline\": float(y_sub.mean()),\n",
    "        \"coef_csv\": coef_csv,\n",
    "        \"pred_csv_MAGI\": pred_csv,\n",
    "        \"roc_png_MAGI\": os.path.abspath(png_path),\n",
    "        \"LASSO_CV_AUC\": float(lasso_cv_auc) if not np.isnan(lasso_cv_auc) else np.nan,\n",
    "        \"LASSO_Refit_AUC\": float(lasso_auc) if not np.isnan(lasso_auc) else np.nan,\n",
    "        \"LASSO_pred_csv\": lasso_pred_csv,\n",
    "        \"LASSO_coef_csv\": lasso_coef_csv,\n",
    "        \"Dual_ROC_png\": dual_png,\n",
    "        \"magi_nonzero_used\": int(magi_nz_feats.size),\n",
    "        \"magi_used_coef_csv\": magi_used_csv,\n",
    "    })\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
