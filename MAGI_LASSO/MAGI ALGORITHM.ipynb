{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d591da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-12-22, YL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List, Union\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# MAGI core: analyze_causal_sequence_py (INT-BASED)\n",
    "# ======================================================================\n",
    "\n",
    "# RIGHT = k (predictor) and LEFT = Y/j\n",
    "def analyze_causal_sequence_py(\n",
    "    df_in: Union[str, pd.DataFrame],\n",
    "    *,\n",
    "    name_map: Dict[str, str] = None,     # kept for compatibility but IGNORED in _int version\n",
    "    events: List[int] = None,            # event IDs to KEEP; if None: auto-detect from *_int cols\n",
    "    force_outcome: int = None,           # if provided and present, force this to be the FINAL node (Y)\n",
    "    lambda_min_count: int = 15           # L-threshold for λ: if n_code < L ⇒ λ_{k,j}=0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    MAGI (Python, INT-BASED) – uses total_effects from DB for T, no 2×2 fallback.\n",
    "    All computations are done on target_concept_code_int / concept_code_int.\n",
    "\n",
    "    Rules:\n",
    "      • T_{kY}:\n",
    "            If `total_effects` column exists:\n",
    "                T_{kY} = mean(total_effects) from row(s) with (target=Y, code=k).\n",
    "                If those rows are missing or total_effects is NaN/≤0/±inf → T_{kY} = 1.\n",
    "            If `total_effects` column does NOT exist at all → T_{kY} = 1 for all k.\n",
    "      • Temporal score:\n",
    "            For each Zi:\n",
    "                score(Zi) = Σ_{Zj≠Zi} [ n_target_before_code(Zi,Zj) - n_code_before_target(Zi,Zj) ]\n",
    "            This is computed from the same counts as your original code,\n",
    "            just via a MultiIndex instead of repeated scans.\n",
    "      • λ_{k,j}:\n",
    "            λ_{k,j} = n_code_target(j,k) / n_code(j,k),\n",
    "            read from rows with (target=j, code=k), with L-threshold on n_code.\n",
    "    \"\"\"\n",
    "    # ── 0) Ingest & basic checks ───────────────────────────────────────────────\n",
    "    df = pd.read_csv(df_in) if isinstance(df_in, str) else df_in.copy()\n",
    "\n",
    "    need_cols = [\n",
    "        \"target_concept_code_int\", \"concept_code_int\",\n",
    "        \"n_code_target\", \"n_code_no_target\",\n",
    "        \"n_target\", \"n_no_target\",\n",
    "        \"n_target_no_code\",\n",
    "        \"n_code\",\n",
    "        \"n_code_before_target\", \"n_target_before_code\",\n",
    "    ]\n",
    "    missing = [c for c in need_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required count columns for MAGI: {', '.join(missing)}\")\n",
    "\n",
    "    has_total_effects = \"total_effects\" in df.columns\n",
    "\n",
    "    # Ensure *_int are numeric / nullable ints\n",
    "    df[\"target_concept_code_int\"] = pd.to_numeric(df[\"target_concept_code_int\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"concept_code_int\"]        = pd.to_numeric(df[\"concept_code_int\"],        errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # name_map intentionally ignored in _int version\n",
    "\n",
    "    # Limit to selected events\n",
    "    if events is None:\n",
    "        arr_t = df[\"target_concept_code_int\"].dropna().unique()\n",
    "        arr_c = df[\"concept_code_int\"].dropna().unique()\n",
    "        # IntegerArray -> list of Python ints\n",
    "        ev_t = [int(x) for x in arr_t]\n",
    "        ev_c = [int(x) for x in arr_c]\n",
    "        events = sorted(set(ev_t) | set(ev_c))\n",
    "    else:\n",
    "        events = [int(e) for e in events]\n",
    "\n",
    "    if len(events) < 2:\n",
    "        raise ValueError(\"Need at least two events.\")\n",
    "\n",
    "    df = df[\n",
    "        df[\"target_concept_code_int\"].isin(events)\n",
    "        & df[\"concept_code_int\"].isin(events)\n",
    "    ].copy()\n",
    "\n",
    "    # Coerce numerics\n",
    "    num_cols = [\n",
    "        \"n_code_target\", \"n_code_no_target\",\n",
    "        \"n_target\", \"n_no_target\", \"n_target_no_code\",\n",
    "        \"n_code\",\n",
    "        \"n_code_before_target\", \"n_target_before_code\",\n",
    "    ]\n",
    "    if has_total_effects:\n",
    "        num_cols.append(\"total_effects\")\n",
    "\n",
    "    for c in num_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # ── 1) Build an indexed edge table ────────────────────────────────────────\n",
    "    edge = (\n",
    "        df.groupby([\"target_concept_code_int\", \"concept_code_int\"], as_index=True)[\n",
    "            [\"n_target_before_code\", \"n_code_before_target\",\n",
    "             \"n_code_target\", \"n_code\"]\n",
    "        ].sum()\n",
    "    )\n",
    "\n",
    "    edge_targets = edge.index.get_level_values(0)\n",
    "\n",
    "    # ── 2) Temporal scores ────────────────────────────────────────────────────\n",
    "    scores: Dict[int, float] = {}\n",
    "    for zi in events:\n",
    "        if zi not in edge_targets:\n",
    "            scores[zi] = 0.0\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            sub = edge.xs(zi, level=\"target_concept_code_int\")  # index = concept_code_int\n",
    "        except KeyError:\n",
    "            scores[zi] = 0.0\n",
    "            continue\n",
    "\n",
    "        s = float(\n",
    "            (sub[\"n_target_before_code\"].fillna(0.0) -\n",
    "             sub[\"n_code_before_target\"].fillna(0.0)).sum()\n",
    "        )\n",
    "        scores[zi] = s\n",
    "\n",
    "    sorted_scores = pd.Series(scores).sort_values(ascending=False)\n",
    "\n",
    "    # Choose outcome Y\n",
    "    if (force_outcome is not None) and (force_outcome in sorted_scores.index):\n",
    "        outcome = int(force_outcome)\n",
    "        temporal_order = [ev for ev in sorted_scores.index if ev != outcome] + [outcome]\n",
    "    else:\n",
    "        outcome = int(sorted_scores.index[0])\n",
    "        temporal_order = [ev for ev in sorted_scores.index if ev != outcome] + [outcome]\n",
    "\n",
    "    events_order = temporal_order\n",
    "    nodes = events_order[:-1]\n",
    "\n",
    "    pos_by_event = {ev: i for i, ev in enumerate(events_order)}\n",
    "\n",
    "    # Pre-filter rows where LEFT == outcome for T_{kY}\n",
    "    if has_total_effects:\n",
    "        dfY = df[df[\"target_concept_code_int\"] == outcome].copy()\n",
    "        dfY[\"total_effects\"] = pd.to_numeric(dfY[\"total_effects\"], errors=\"coerce\")\n",
    "    else:\n",
    "        dfY = None\n",
    "\n",
    "    # ── 3) T and λ ─────────────────────────────────────────────────────────────\n",
    "    T_val = pd.Series(0.0, index=nodes, dtype=float)\n",
    "    D_val = pd.Series(np.nan, index=nodes, dtype=float)\n",
    "    lambda_l: Dict[int, pd.Series] = {}\n",
    "\n",
    "    for k in nodes:\n",
    "        # T_{kY}\n",
    "        if has_total_effects:\n",
    "            row_Yk = dfY[dfY[\"concept_code_int\"] == k]\n",
    "            if row_Yk.empty:\n",
    "                T_val.loc[k] = 1.0\n",
    "            else:\n",
    "                T_col = pd.to_numeric(row_Yk[\"total_effects\"], errors=\"coerce\")\n",
    "                T_col = T_col.replace([np.inf, -np.inf], np.nan)\n",
    "                T_clean = T_col.dropna()\n",
    "                if T_clean.empty:\n",
    "                    T_val.loc[k] = 1.0\n",
    "                else:\n",
    "                    T_db = float(T_clean.mean())\n",
    "                    if (not np.isfinite(T_db)) or (T_db <= 0):\n",
    "                        T_db = 1.0\n",
    "                    T_val.loc[k] = T_db\n",
    "        else:\n",
    "            T_val.loc[k] = 1.0\n",
    "\n",
    "        # λ_{k,j}\n",
    "        pos_k = pos_by_event[k]\n",
    "        js = events_order[pos_k + 1 : -1] if pos_k < len(events_order) - 1 else []\n",
    "\n",
    "        lam_pairs = {}\n",
    "        for j in js:\n",
    "            key = (j, k)\n",
    "            if key not in edge.index:\n",
    "                lam_pairs[j] = 0.0\n",
    "                continue\n",
    "\n",
    "            row_jk = edge.loc[key]\n",
    "            num = float(row_jk[\"n_code_target\"])\n",
    "            den = float(row_jk[\"n_code\"])\n",
    "\n",
    "            if (den <= 0) or (den < lambda_min_count):\n",
    "                lam_pairs[j] = 0.0\n",
    "                continue\n",
    "\n",
    "            lam = num / den\n",
    "            if not np.isfinite(lam):\n",
    "                lam = 0.0\n",
    "            lam_pairs[j] = float(min(max(lam, 0.0), 1.0))\n",
    "\n",
    "        lambda_l[k] = pd.Series(lam_pairs, dtype=float)\n",
    "\n",
    "    # ── 4) Backward recursion for D ────────────────────────────────────────────\n",
    "    if len(nodes) >= 1:\n",
    "        last_anc = nodes[-1]\n",
    "        D_val.loc[last_anc] = T_val.loc[last_anc]\n",
    "\n",
    "    if len(nodes) > 1:\n",
    "        for k in list(reversed(nodes[:-1])):\n",
    "            lam_vec = lambda_l.get(k, pd.Series(dtype=float))\n",
    "            downstream = list(lam_vec.index)\n",
    "            lam_vals = lam_vec.reindex(downstream).fillna(0.0).to_numpy()\n",
    "            D_down  = pd.to_numeric(D_val.reindex(downstream),\n",
    "                                    errors=\"coerce\").fillna(0.0).to_numpy()\n",
    "\n",
    "            num = T_val.loc[k] - float(np.nansum(lam_vals * D_down))\n",
    "            den = 1.0 - float(np.nansum(lam_vals))\n",
    "\n",
    "            if (not np.isfinite(den)) or den == 0.0:\n",
    "                D_val.loc[k] = T_val.loc[k]\n",
    "            else:\n",
    "                tmp = num / den\n",
    "                D_val.loc[k] = tmp if np.isfinite(tmp) else T_val.loc[k]\n",
    "\n",
    "    # ── 5) Logistic link (β) and predict_proba ─────────────────────────────────\n",
    "    resp_rows = df[df[\"target_concept_code_int\"] == outcome]\n",
    "    n_t = float(pd.to_numeric(resp_rows[\"n_target\"],      errors=\"coerce\").max()) if not resp_rows.empty else np.nan\n",
    "    n_n = float(pd.to_numeric(resp_rows[\"n_no_target\"],   errors=\"coerce\").max()) if not resp_rows.empty else np.nan\n",
    "    denom = n_t + n_n\n",
    "    p_y = 0.5 if (not np.isfinite(denom) or denom <= 0) else (n_t / denom)\n",
    "    p_y = min(max(p_y, 1e-12), 1 - 1e-12)\n",
    "    beta_0 = float(np.log(p_y / (1 - p_y)))\n",
    "\n",
    "    D_clean = pd.to_numeric(D_val, errors=\"coerce\").astype(float)\n",
    "    beta_vals = np.log(D_clean.where(D_clean > 0.0)) \\\n",
    "                    .replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    coef_df = pd.DataFrame({\n",
    "        \"predictor\": list(beta_vals.index) + [\"(intercept)\"],\n",
    "        \"beta\":      list(beta_vals.values) + [beta_0],\n",
    "    })\n",
    "\n",
    "    predictors = list(beta_vals.index)\n",
    "    beta_vec = beta_vals.values\n",
    "\n",
    "    def predict_proba(Z):\n",
    "        \"\"\"\n",
    "        Compute P(Y=1|Z) using: logit P = β0 + Σ_k β_k Z_k.\n",
    "        Here Z keys should be concept_code_int IDs.\n",
    "        \"\"\"\n",
    "        def sigmoid(x):\n",
    "            x = np.clip(x, -700, 700)\n",
    "            return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "        if isinstance(Z, pd.DataFrame):\n",
    "            M = Z.reindex(columns=predictors, fill_value=0.0) \\\n",
    "                 .astype(float).to_numpy()\n",
    "            return sigmoid(beta_0 + M @ beta_vec)\n",
    "\n",
    "        if isinstance(Z, (dict, pd.Series)):\n",
    "            v = np.array([float(Z.get(p, 0.0)) for p in predictors], dtype=float)\n",
    "            return float(sigmoid(beta_0 + float(v @ beta_vec)))\n",
    "\n",
    "        arr = np.asarray(Z, dtype=float)\n",
    "        if arr.ndim == 1:\n",
    "            if arr.size != len(predictors):\n",
    "                raise ValueError(f\"Expected {len(predictors)} features in order: {predictors}\")\n",
    "            return float(sigmoid(beta_0 + float(arr @ beta_vec)))\n",
    "        if arr.ndim == 2:\n",
    "            if arr.shape[1] != len(predictors):\n",
    "                raise ValueError(f\"Expected shape (*,{len(predictors)}), got {arr.shape}\")\n",
    "            return sigmoid(beta_0 + arr @ beta_vec)\n",
    "\n",
    "        raise ValueError(\"Unsupported input for predict_proba\")\n",
    "\n",
    "    return {\n",
    "        \"sorted_scores\": sorted_scores,\n",
    "        \"temporal_order\": events_order,\n",
    "        \"order_used\": events_order,\n",
    "        \"T_val\": T_val,\n",
    "        \"D_val\": D_val,\n",
    "        \"lambda_l\": lambda_l,\n",
    "        \"coef_df\": coef_df,\n",
    "        \"beta_0\": beta_0,\n",
    "        \"beta\": pd.Series(beta_vec, index=predictors, dtype=float),\n",
    "        \"logit_predictors\": predictors,\n",
    "        \"predict_proba\": predict_proba,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d9807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
